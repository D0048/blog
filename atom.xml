<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>D0048</title>
  
  <subtitle>A record of thoughts, ideas, solutions and traps</subtitle>
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="https://d0048.github.io/blog/"/>
  <updated>2017-12-30T15:19:19.558Z</updated>
  <id>https://d0048.github.io/blog/</id>
  
  <author>
    <name>D0048</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Fix Xlib:  extension GLX missing on display :8 error running Gui programs</title>
    <link href="https://d0048.github.io/blog/2017/12/25/Fix-Xlib-extension-GLX-missing-on-display-8-error-running-Gui-programs/"/>
    <id>https://d0048.github.io/blog/2017/12/25/Fix-Xlib-extension-GLX-missing-on-display-8-error-running-Gui-programs/</id>
    <published>2017-12-25T03:53:57.000Z</published>
    <updated>2017-12-30T15:19:19.558Z</updated>
    
    <content type="html"><![CDATA[<p>After installing both Bumblebee and Nvdia Prime like <a href="https://d0048.github.io/blog/2017/12/10/Ubuntu-16-04-ultimate-dual-graphic-card-solution-with-newest-nvidia-proprietary-drivers-switchable-without-logout/">this</a>, an error of:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Xlib:  extension <span class="string">"GLX"</span> missing on display <span class="string">":8"</span>.</div></pre></td></tr></table></figure></p><p>is got when attempting to run an gui program. </p><p>The most effective solution found is to follow this solution <a href="https://github.com/Bumblebee-Project/Bumblebee/issues/759" target="_blank" rel="external">here</a> given by sapjunior, but with slight modification. </p><p>Here’s the solution worked for me:<br><strong><em>Still all the driver version numbers need to be replaced with yours!</em></strong></p><ol><li><p>Add the following to <code>/etc/modprobe.d/bumblebee.conf</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">alias</span> nvidia-drm nvidia_364_drm</div><div class="line"><span class="built_in">alias</span> nvidia-uvm nvidia_364_uvm</div><div class="line"><span class="built_in">alias</span> nvidia-modeset nvidia_364_modeset</div><div class="line">remove nvidia rmmod nvidia-drm nvidia-modeset nvidia-uvm nvidia</div></pre></td></tr></table></figure></li><li><p>Perform the following and choose the one with <code>mesa</code> inside. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo update-alternatives --config x86_64-linux-gnu_gl_conf</div><div class="line">sudo update-alternatives --config x86_64-linux-gnu_egl_conf</div><div class="line">sudo update-alternatives --config i386-linux-gnu_gl_conf</div></pre></td></tr></table></figure></li><li><p>Refresh shared libiary status with <code>sudo ldconfig</code>.</p></li></ol><p>2017/12/25</p><p>Add: seems like this setting will be reset after reboot… Just add the following command s on boot:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo update-alternatives --<span class="built_in">set</span> x86_64-linux-gnu_gl_conf /usr/lib/x86_64-linux-gnu/mesa/ld.so.conf</div><div class="line">sudo update-alternatives --<span class="built_in">set</span> x86_64-linux-gnu_egl_conf /usr/lib/x86_64-linux-gnu/mesa-egl/ld.so.conf</div><div class="line">sudo update-alternatives --<span class="built_in">set</span> i386-linux-gnu_gl_conf /usr/lib/i386-linux-gnu/mesa/ld.so.conf</div><div class="line">sudo ldconfig</div></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;After installing both Bumblebee and Nvdia Prime like &lt;a href=&quot;https://d0048.github.io/blog/2017/12/10/Ubuntu-16-04-ultimate-dual-graphic-
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu 16.04 ultimate dual graphic card solution with newest nvidia proprietary drivers switchable without logout</title>
    <link href="https://d0048.github.io/blog/2017/12/10/Ubuntu-16-04-ultimate-dual-graphic-card-solution-with-newest-nvidia-proprietary-drivers-switchable-without-logout/"/>
    <id>https://d0048.github.io/blog/2017/12/10/Ubuntu-16-04-ultimate-dual-graphic-card-solution-with-newest-nvidia-proprietary-drivers-switchable-without-logout/</id>
    <published>2017-12-10T14:47:15.000Z</published>
    <updated>2017-12-25T04:06:54.236Z</updated>
    
    <content type="html"><![CDATA[<p>Finally I got it working. Using both nvidia-prime and bumblebee at the same time to allow switches between the two graphic cards (intel and nvidia) in both per-application-without-logout and whole-system-with-logout manner. My cuda also stays working at both mode. </p><p>The following are the steps. </p><ol><li><p>Add newest nvidia-driver ppa: <code>sudo add-apt-repository ppa:graphics-drivers/ppa;sudo apt update</code>.</p></li><li><p>Install the proprietary driver(in my case, 384, larger index should means newer) and nvidia-prime: <code>sudo apt install nvidia-384 nvidia-prime</code>.</p></li><li><p>[optional] Add prime-indicator ppa and install <code>sudo add-apt-repository ppa:nilarimogard/webupd8;sudo apt update;sudo apt install prime-indicator-plus;</code></p></li><li><p>Reboot and the graphic cards should be able to be switchable with the indicator or x-org-setting from the dash menu. But it requires a reboot to perform the switch. If that’s not satisfactory and the user want more flexible control, proceed. If not, stop here. </p></li><li><p>Install bbswitch and bumblebee: <code>sudo apt install bbswitch-dkms bumblebee bumblebee-nvidia</code>.</p></li><li><p>Configure bumblebee to work. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo gpasswd -a <span class="variable">$USER</span> bumblebee</div><div class="line">sudo systemctl <span class="built_in">enable</span> bumblebeed</div></pre></td></tr></table></figure></li></ol><p>open the config file <code>sudo gedit /etc/bumblebee/bumblebee.conf</code> and edit:<br><code>Driver=</code> $\rightarrow$ <code>Driver=nvidia</code><br><strong>Remember to replace all <code>384</code> to your driver index</strong><br><code>KernelDriver=nvidia-384</code><br><code>LibraryPath=/usr/lib/nvidia-384:/usr/lib32/nvidia-384</code><br><code>XorgModulePath=/usr/lib/nvidia-384/xorg,/usr/lib/xorg/modules</code></p><p>open the config file <code>/etc/modprobe.d/bumblebee.conf</code> and add:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">blacklist nvidia-384</div><div class="line">blacklist nvidia-384-updates</div><div class="line">blacklist nvidia-experimental-384</div></pre></td></tr></table></figure></p><ol><li><p>Reboot and prey.</p></li><li><p>If everything goes right, you should be able to use <code>optirun COMMAND</code> to run an application using the nvidia graphic card even if you disabled the card and set to use the intel graphic card in the nvidia-prime setting. </p></li><li><p>Try <code>optirun COMMAND</code> or <code>primusrun COMMAND</code> and see if everything works. It’s said that the former is of better performances but its actually 3 times slower on my machine.</p></li><li><p>Remember to turn off the power of nvidia GPU after using it through the indicator to save power.</p></li></ol><p>2017/12/10</p><p><strong>Add: After updating to nvidia-387, except changing the config files, a manual power on through prime indicator seems to be necessary everytime before use. </strong></p><p>Add: To solve the error: <code>Xlib:  extension &quot;GLX&quot; missing on display &quot;:8&quot;.</code>, see <a href="https://d0048.github.io/blog/2017/12/25/Fix-Xlib-extension-GLX-missing-on-display-8-error-running-Gui-programs/">here</a>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Finally I got it working. Using both nvidia-prime and bumblebee at the same time to allow switches between the two graphic cards (intel a
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>Solution to AttributeError ProgressBar object has no attribute finished error using ubuntu-make</title>
    <link href="https://d0048.github.io/blog/2017/11/30/AttributeError-ProgressBar-object-has-no-attribute-finished-error-using-ubuntu-make/"/>
    <id>https://d0048.github.io/blog/2017/11/30/AttributeError-ProgressBar-object-has-no-attribute-finished-error-using-ubuntu-make/</id>
    <published>2017-11-30T11:12:31.000Z</published>
    <updated>2017-11-30T11:23:24.500Z</updated>
    
    <content type="html"><![CDATA[<p>It seems like the umake version contained in the ubuntu 16.04 ppa <code>ppa:ubuntu-desktop/ubuntu-make</code> breaks due to a change in the API of the python <code>ProgressBar</code> module…</p><p>The error log looks like this: </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">N/A% (0 of 100) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--Downloading and installing requirements</div><div class="line">ERROR: Unhandled exception</div><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"/usr/lib/python3/dist-packages/umake/tools.py"</span>, line 158, <span class="keyword">in</span> wrapper</div><div class="line">    <span class="keyword">function</span>(*args, **kwargs)</div><div class="line">  File <span class="string">"/usr/lib/python3/dist-packages/umake/frameworks/baseinstaller.py"</span>, line 288, <span class="keyword">in</span> get_progress</div><div class="line">    <span class="keyword">if</span> not self.pbar.finished:  <span class="comment"># drawing is delayed, so ensure we are not done first</span></div><div class="line">AttributeError: <span class="string">'ProgressBar'</span> object has no attribute <span class="string">'finished'</span></div><div class="line">ERROR: Unhandled exception</div><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"/usr/lib/python3/dist-packages/umake/tools.py"</span>, line 158, <span class="keyword">in</span> wrapper</div><div class="line">    <span class="keyword">function</span>(*args, **kwargs)</div><div class="line">  File <span class="string">"/usr/lib/python3/dist-packages/umake/frameworks/baseinstaller.py"</span>, line 288, <span class="keyword">in</span> get_progress</div><div class="line">    <span class="keyword">if</span> not self.pbar.finished:  <span class="comment"># drawing is delayed, so ensure we are not done first</span></div><div class="line">AttributeError: <span class="string">'ProgressBar'</span> object has no attribute <span class="string">'finished'</span></div></pre></td></tr></table></figure><p>However, I failed to find a file corresponding to <code>File &quot;/usr/lib/python3/dist-packages/umake/frameworks/baseinstaller.py&quot;</code> in the github repo, thus failing to start an pr/issue. </p><p>For those who encounter similar issue, here’s the quick fix…</p><ol><li><p>Use your favorite editor and root access to open the file <code>/usr/lib/python3/dist-packages/umake/frameworks/baseinstaller.py</code>, e.g <code>sudo gedit /usr/lib/python3/dist-packages/umake/frameworks/baseinstaller.py</code>. </p></li><li><p>Go to line 288.</p></li><li><p>Change the line <code>if not self.pbar.finished:  # drawing is delayed, so ensure we are not done first</code> to <code>if True:</code>, save and quit. </p></li><li><p>The progress bar may looks kinda broken after the fix, but will have no interruption to any installation…</p></li></ol><p><code>2017/11/30</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;It seems like the umake version contained in the ubuntu 16.04 ppa &lt;code&gt;ppa:ubuntu-desktop/ubuntu-make&lt;/code&gt; breaks due to a change in t
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>Setting up the FRC development environment on ubuntu 16.04</title>
    <link href="https://d0048.github.io/blog/2017/11/30/Setting-up-the-FRC-development-environment-on-ubuntu-16-04/"/>
    <id>https://d0048.github.io/blog/2017/11/30/Setting-up-the-FRC-development-environment-on-ubuntu-16-04/</id>
    <published>2017-11-30T01:21:42.000Z</published>
    <updated>2017-12-04T11:23:04.025Z</updated>
    
    <content type="html"><![CDATA[<p>This is a record setting up the FRC development environment for C++/Java for the comp in 2018. </p><ol><li><p>Normally setting up the system, install anything one may need like <code>git/svn/browser</code>… and so on. </p></li><li><p>Add FRC cmake tool ppa: <code>sudo add-apt-repository ppa:wpilib/toolchain-beta</code>, download package list: <code>sudo apt update</code>, download toolchains <code>sudo apt install frc-toolchain</code>.</p></li><li><p>Download eclipse <code>sudo apt install eclipse</code>.</p></li><li><p>Download C++ support for eclipse <code>sudo apt install sudo apt install eclipse-cdt*</code> if using bash(default). If using zsh, use <code>sudo apt install eclipse-cdt\*</code>.</p></li><li><p>Install the IDE/editor wanted. In my case: </p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sudo add-apt-repository ppa:ubuntu-desktop/ubuntu-make;</div><div class="line">sudo add-apt-repository ppa:jonathonf/vim;</div><div class="line">sudo apt update;</div><div class="line">sudo apt install ubuntu-make vim;</div><div class="line">umake ide eclipse</div></pre></td></tr></table></figure><p><strong>If umake went wrong(which suppose to in my current version), refer <a href="https://d0048.github.io/blog/2017/11/30/AttributeError-ProgressBar-object-has-no-attribute-finished-error-using-ubuntu-make/">this link</a> to fix a bug of umake</strong></p><ol><li><p>Open eclipse and install the CDT plugin(for cpp development), Lib for FRC, and vim mode.<br><code>help-&gt;install new software-&gt;add-&gt;Enter &quot;http://download.eclipse.org/tools/cdt/releases/9.3&quot; for eclipse oxygen -&gt; select all -&gt; install...</code><br><code>help-&gt;install new software-&gt;add-&gt;Enter &quot; http://vrapper.sourceforge.net/update-site/stable&quot; for eclipse oxygen -&gt; select all -&gt; install...</code><br><code>help-&gt;install new software-&gt;add-&gt;Enter &quot; http://first.wpi.edu/FRC/roborio/release/eclipse/&quot; for eclipse oxygen -&gt; select all -&gt; install...</code></p></li><li><p>Install <code>LabView</code> started with downloading the standard linux ISO at the official website of NI. </p></li><li><p>Unluckily, the official one only support redhat series thus our debian series will not fit. We need to convert those <code>.rpm</code> packages inside the ISO into <code>.deb</code> so we can install and manage them with our native package manager. (Although one can manually unpack and install them, it would be a great pain…)</p></li><li><p>Start by installing tools: <code>sudo apt install fakeroot alien</code>.</p></li><li><p>Then extract or mount the file inside the ISO and copy everything in the root dir (inside the i386 folder for 32 bit installations) to a any working directory. </p></li><li><p>Run <code>fakeroot alien -k --script ./*.rpm</code> after entering the working directory chosen. </p></li><li><p>Wait till finish, and <code>sudo dpkg -i *.deb</code>. And LabView should be installed. </p></li><li><p>Now we need to install the FRC Plugin for LabView. </p></li><li><p>Unfortunately, the current version of FRC Plugin does not support Linux OS…Tooooooooooo bad.</p></li></ol><p><code>2017/12/4</code> TO BE CONTINUED</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This is a record setting up the FRC development environment for C++/Java for the comp in 2018. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Normally setting up the s
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="FRC" scheme="https://d0048.github.io/blog/tags/FRC/"/>
    
  </entry>
  
  <entry>
    <title>Make touchegg work on ubuntu unity/gnome desktops</title>
    <link href="https://d0048.github.io/blog/2017/11/23/Make-touchegg-work-on-ubuntu-unity-gnome-desktops/"/>
    <id>https://d0048.github.io/blog/2017/11/23/Make-touchegg-work-on-ubuntu-unity-gnome-desktops/</id>
    <published>2017-11-23T03:23:07.000Z</published>
    <updated>2017-11-23T03:28:31.289Z</updated>
    
    <content type="html"><![CDATA[<p>It seems like the unity DE somehow blocks the mouse gesture for itself, thus most of the other multi-touch recognizers can not catch the events. </p><p>To disable this, the unity multi-touch support need to be completely disabled:</p><ol><li>Install <code>dconf-editor</code>, using <code>apt install dconf-editor -y</code>.</li><li>Launch <code>dconf-editor</code> via command line.</li><li>Go to <code>com-&gt;canonical-&gt;unity-&gt;gestures</code> and disable everything inside.</li></ol><p>Now tools like toughegg could catch touchpad events as normal. </p><p><code>2017/11/23</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;It seems like the unity DE somehow blocks the mouse gesture for itself, thus most of the other multi-touch recognizers can not catch the 
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>A Brief Summary of the Godel&#39;s Incompleteness Theorems</title>
    <link href="https://d0048.github.io/blog/2017/11/21/A-Brief-Summary-of-the-Godel-s-Incompleteness-Theorems/"/>
    <id>https://d0048.github.io/blog/2017/11/21/A-Brief-Summary-of-the-Godel-s-Incompleteness-Theorems/</id>
    <published>2017-11-21T09:00:50.000Z</published>
    <updated>2017-11-21T09:31:20.093Z</updated>
    
    <content type="html"><![CDATA[<p>$\forall Axiomatic_System \\=&gt;  (!Completeness) OR (!Consistency)$</p><blockquote><p>There are inherent limitations of every formal axiomatic system containing <strong>basic arithmetic</strong>.</p></blockquote><p><br></p><h4 id="Completeness"><a href="#Completeness" class="headerlink" title="Completeness:"></a><strong>Completeness</strong>:</h4><blockquote><p>for any statement in the axioms’ language, that statement or its negation is provable from the axioms</p></blockquote><h4 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency:"></a><strong>Consistency</strong>:</h4><blockquote><p>there is no statement such that both the statement and its negation are provable from the axioms</p></blockquote><h4 id="First-incompleteness-theorem"><a href="#First-incompleteness-theorem" class="headerlink" title="First incompleteness theorem:"></a><strong>First incompleteness theorem</strong>:</h4><p>The conclusion is: there will always be elements whether </p><ul><li><em>both belong and don’t belong to a set</em> =&gt; Breaking <em>consistancy</em>. </li><li><em>can not be classified</em> =&gt; Breaking the <em>completeness</em>.</li></ul><blockquote><p>Any consistent formal system F within which a certain amount of elementary arithmetic can be carried out is incomplete; i.e., there are statements of the language of F which can neither be proved nor disproved in F.</p></blockquote><p><strong>Gödel sentence</strong> =&gt; The above mentioned statements that either unprovable or could be proved to be both true/false.</p><ul><li>The Gödel sentence is designed to refer, indirectly, to itself. </li><li>Define itself as something that’s not itself in itself. </li><li><p>Construction:</p><ul><li>$T \leftrightarrow \lnot True(T)$</li></ul></li><li><p>With inconsistency $B\lor\lnot B$, we can prove anything:</p><ul><li>$B\lor\lnot B$</li><li>$def: \lnot A \rightarrow (B \lor \lnot B)$</li><li>$\lnot(B\lor \neg B)\rightarrow \neg \neg A$</li><li>$B \land \neg B \rightarrow A$</li><li>$B \land \neg B$</li></ul></li></ul><h4 id="Second-incompleteness-theorem"><a href="#Second-incompleteness-theorem" class="headerlink" title="Second incompleteness theorem:"></a><strong>Second incompleteness theorem</strong>:</h4><h4 id="Solution"><a href="#Solution" class="headerlink" title="Solution:"></a><strong>Solution</strong>:</h4><p><a href="https://plato.stanford.edu/entries/type-theory/" target="_blank" rel="external">The Type Theory</a>, Where operators are put into types and they can not be used to describle those that are in the same type, including themselves. This way, the <em>Russell Paradox</em>, using an operation in a statement pointing to the statment itself as a Godel sentence, is simply invalid. </p><p>Reference: <a href="https://en.wikipedia.org/wiki/Gödel&#39;s_incompleteness_theorems" target="_blank" rel="external">Wikipedia</a>, <a href="https://www.zhihu.com/question/27528796" target="_blank" rel="external">Zhihu1</a>, <a href="https://www.zhihu.com/question/20511488/answer/133390930" target="_blank" rel="external">Zhihu2</a></p><p>2017/11/21</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;$\forall Axiomatic_System \\=&amp;gt;  (!Completeness) OR (!Consistency)$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There are inherent limitations of every formal 
      
    
    </summary>
    
    
      <category term="Math" scheme="https://d0048.github.io/blog/tags/Math/"/>
    
  </entry>
  
  <entry>
    <title>Preventing CPU/IO Intensive Programs Blocking Linux Gui</title>
    <link href="https://d0048.github.io/blog/2017/11/19/Preventing-CPU-IO-Intensive-Programs-Blocking-Linux-Gui/"/>
    <id>https://d0048.github.io/blog/2017/11/19/Preventing-CPU-IO-Intensive-Programs-Blocking-Linux-Gui/</id>
    <published>2017-11-19T06:05:40.000Z</published>
    <updated>2017-11-19T06:31:20.710Z</updated>
    
    <content type="html"><![CDATA[<h3 id="What-for"><a href="#What-for" class="headerlink" title="What for?"></a>What for?</h3><p>The fact that the linux kernel does NOT come with a GUI and the GUIs used are third  party components, their default priority levels (or nice level, which is user-space name for priority.) are the same as any other user space programs. This may cause the GUI to freeze when performing CPU/IO intensive jobs since they all run at the same priority level. </p><h3 id="What’s-nice-value-priority"><a href="#What’s-nice-value-priority" class="headerlink" title="What’s nice value/priority?"></a>What’s nice value/priority?</h3><p>To prevent that, we need to change the nice level, where the priority of a process equals <code>NICE_VALUE+20</code>. That’s said, higher priority level, same as higher nice level, creates a less prior job. </p><p>Usually run a program with <code>nice -n $NI_VALUE $COMMAND</code> starts a program with a given nice value. <code>renice -n NI_VALUE $PID</code> changes the priority level of a process with the given pid. (multiple pid could be given to change them all) </p><p>Sub-processes owns the same nice level with their parents.</p><h3 id="What-about-IO"><a href="#What-about-IO" class="headerlink" title="What about IO?"></a>What about IO?</h3><p>The above works for CPU priority only. For IO control, the default priority will be <code>cpu_priority / 5</code> and one can always change that using <code>ionice</code>.</p><h3 id="To-make-them-automatic"><a href="#To-make-them-automatic" class="headerlink" title="To make them automatic"></a>To make them automatic</h3><p>I recommend putting the pivotal GUI components into startup script or <code>crontab -e</code>(cron needed to be installed) like this:</p><pre>#"sudo crontab -e" to input* * * * * renice -n -4 -p $(pidof vivaldi-bin)* * * * * renice -n -8 -p $(pidof nautilus)* * * * * renice -n -8 -p $(pidof Xorg)* * * * * renice -n -8 -p $(pidof compiz)</pre><p>2017/11/19</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;What-for&quot;&gt;&lt;a href=&quot;#What-for&quot; class=&quot;headerlink&quot; title=&quot;What for?&quot;&gt;&lt;/a&gt;What for?&lt;/h3&gt;&lt;p&gt;The fact that the linux kernel does NOT come
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>|failed to start docker application container engine| error after upgrade on ubuntu</title>
    <link href="https://d0048.github.io/blog/2017/11/16/failed-to-start-docker-application-container-engine-error-after-upgrade-on-ubuntu/"/>
    <id>https://d0048.github.io/blog/2017/11/16/failed-to-start-docker-application-container-engine-error-after-upgrade-on-ubuntu/</id>
    <published>2017-11-16T02:47:52.000Z</published>
    <updated>2017-11-16T02:50:30.528Z</updated>
    
    <content type="html"><![CDATA[<p>Referring to this (issue)[<a href="https://github.com/moby/moby/issues/29179" target="_blank" rel="external">https://github.com/moby/moby/issues/29179</a>], added <code>--storage-driver=overlay</code> at the end of the line defining <code>ExecStart</code> and tried <code>sudo systemctl daemon-reload;sudo systemctl daemon-reload ;sudo apt -f install</code>.</p><p>Worked for me.<br>2017/11/16</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Referring to this (issue)[&lt;a href=&quot;https://github.com/moby/moby/issues/29179&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/moby/moby
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>Rejailbreak Kindle PaperWhite3 After Automatic Upgrade to 5.9.2</title>
    <link href="https://d0048.github.io/blog/2017/11/15/Rejailbreak-Kindle-PaperWhite3-After-Automatic-Upgrade-to-5-9-2/"/>
    <id>https://d0048.github.io/blog/2017/11/15/Rejailbreak-Kindle-PaperWhite3-After-Automatic-Upgrade-to-5-9-2/</id>
    <published>2017-11-15T03:08:09.000Z</published>
    <updated>2017-11-15T03:19:37.848Z</updated>
    
    <content type="html"><![CDATA[<p>My kindle pw3 seems to be automatically updated from 5.9.1 to 5.9.2 and I am unable to run KUAL anymore. To fix this, the following is performed and I am not sure whether any of these steps are necessary.But I did get everything back without losing any data/plugins.</p><ol><li><p>Applied a jailbreak hotfix <code>Update_jailbreak_hotfix_1.14_nomax_install.bin</code>. File found at <a href="https://bookfere.com/post/576.html" target="_blank" rel="external">here</a>. Patched by copying it to the root fs mounted on computer and manually select “update” in menu.</p></li><li><p>Applied <code>Update_KUALBooklet_v2.7_install.bin</code>. File found at <a href="https://bookfere.com/post/311.html" target="_blank" rel="external">here</a>. Patched by copying it to <code>/mrpackages</code> and searching <code>;log mrpi</code>. </p></li></ol><p>This process is recorded hoping to be helpful. Do notice that your devices may not work just as mine and I will not be responsible for any following consequences happened to your device.</p><p>2017/11/15</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;My kindle pw3 seems to be automatically updated from 5.9.1 to 5.9.2 and I am unable to run KUAL anymore. To fix this, the following is pe
      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>Use System Memory Together with Graphic Memory in TensorFlow</title>
    <link href="https://d0048.github.io/blog/2017/11/08/Use-System-Memory-Together-with-Graphic-Memory-in-TensorFlow/"/>
    <id>https://d0048.github.io/blog/2017/11/08/Use-System-Memory-Together-with-Graphic-Memory-in-TensorFlow/</id>
    <published>2017-11-08T02:52:25.000Z</published>
    <updated>2017-11-08T03:05:53.808Z</updated>
    
    <content type="html"><![CDATA[<p>The default options in tensorflow uses graphic memories only and all the tensors are allocated on boot. These are relatively faster, but are also disaster when using a graphic card with lower memories, and I am always getting OOMs from my model.</p><p>There are two ways to ease the issue, which are to enable tensorflow to utilize system memory and disable tensorflow to allocated all memory blocks on boot. </p><pre>    config = tf.ConfigProto()    config.gpu_options.allow_growth = True    config.gpu_options.per_process_gpu_memory_fraction = 0.9    with tf.Session(config=config) as sess:        code to run...        pass</pre><p>The attribute <code>config.gpu_options.per_process_gpu_memory_fraction</code> specifies the fraction of maximum graphic memory to use before using system memory.</p><p>2017/11/8</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;The default options in tensorflow uses graphic memories only and all the tensors are allocated on boot. These are relatively faster, but 
      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="ML" scheme="https://d0048.github.io/blog/tags/ML/"/>
    
      <category term="Python" scheme="https://d0048.github.io/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Prevent Blocking When Using PyPlot</title>
    <link href="https://d0048.github.io/blog/2017/11/02/Prevent-Blocking-When-Using-PyPlot/"/>
    <id>https://d0048.github.io/blog/2017/11/02/Prevent-Blocking-When-Using-PyPlot/</id>
    <published>2017-11-02T12:58:55.000Z</published>
    <updated>2017-11-02T13:05:28.204Z</updated>
    
    <content type="html"><![CDATA[<p>After display logic, call <code>imshow()</code> with parameter <code>block=False</code>.<br>2017/11/2</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;After display logic, call &lt;code&gt;imshow()&lt;/code&gt; with parameter &lt;code&gt;block=False&lt;/code&gt;.&lt;br&gt;2017/11/2&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="Python" scheme="https://d0048.github.io/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Thoughts For Possible New Network Structures</title>
    <link href="https://d0048.github.io/blog/2017/10/27/Thoughts-For-Possible-New-Network-Structures/"/>
    <id>https://d0048.github.io/blog/2017/10/27/Thoughts-For-Possible-New-Network-Structures/</id>
    <published>2017-10-27T14:21:03.000Z</published>
    <updated>2017-11-21T08:56:50.653Z</updated>
    
    <content type="html"><![CDATA[<h2 id="These-are-my-own-ideas-of-how-might-the-neural-network-architecture-may-be-improved-as-a-note-reminding-my-further-implementation-of-them"><a href="#These-are-my-own-ideas-of-how-might-the-neural-network-architecture-may-be-improved-as-a-note-reminding-my-further-implementation-of-them" class="headerlink" title="These are my own ideas of how might the neural network architecture may be improved, as a note reminding my further implementation of them"></a>These are my own ideas of how might the neural network architecture may be improved, as a note reminding my further implementation of them</h2><h3 id="Measure-for-Overfitting"><a href="#Measure-for-Overfitting" class="headerlink" title="Measure for Overfitting"></a>Measure for Overfitting</h3><p><strong><em>TODO</em></strong>: Add measure in respect to acc.<br><strong><em>TODO</em></strong>: Compare $O$ with normal CNN/DNN.</p><p>We does need some measure to see if/how the network is overfitting the training data.</p><p>My first thought is just use $O=LOSS(X_{train})-LOSS(X_{test})$. This seems to be working, and the value stays at around $0\pm0.04$, which means sometimes the network performs better in the training set($O&gt;0$) and sometimes the opposite($)&lt;0$).</p><p>However, after accuracy reaches $99.2\%$, the frequency of observing a positive overfit index $O$ increases and the average index also increase. </p><p><strong>To compare this index with the overfitting condition of other networks</strong>, I need to first somehow add the accuracy into the calculation of the index and then compare them on other architectures.<br>2017/11/21</p><h3 id="Generator-For-Cheating-a-Network"><a href="#Generator-For-Cheating-a-Network" class="headerlink" title="Generator For Cheating a Network"></a>Generator For Cheating a Network</h3><p>What would happen if we first train a classifier to classify image, and then train another network where it distort an input image to maximize the change in the estimation done by the fore-mentioned classifier at the same time minimize the distortion to the image?</p><p>This could be implemented using a new cost function for the second network.</p><p>Implementing.<br>2017/10/27</p><p>I failed to implement this structure in tensorflow in that rather than an actual value, I seems to be getting the uninitialized tensor representation of the output rather than the actual value and I failed to replace the input of the original network with that tensor.<br>2017/10/29</p><p>I found the Generative Adversarial Network (GAN) model which there isn’t that much of a difference between my idea and the model. However, using another network to probe the weak points of an existing network is likely to be a possible idea of improving it.<br>2017/10/30</p><p>This looks like a possible way of modifying the GAN model in that while the discriminator and the generator in the original GAN model works against each other, maybe we can make the discriminator to to create augmented data where it previously wrongly classified. Testing.<br>2017/10/31</p><p>I’m pretty sure this will work, but there are more to it. If I am to train a generator to modify the minimum amount to a picture and at the same time cheating the discriminator, this may work. However, if I am to use the modified image to retrain the network, things may not be as the same… A badly written <code>6</code> might be twisted into something like <code>8</code> from even human perspective and training the discriminator with the image of <code>8</code> and label of <code>6</code> is not likely to improve its performance.</p><p>However, adding the regularization term forcing the generated image to be different from the training set may be a good idea for generators to generate hopefully more creative samples. To be tested, too.<br>2017/11/1</p><p>This is indeed different from regular gan. It looks working but further experiments are to be done.<br>2017/11/2</p><p>Seems working. Work hanged for something else.<br>2017/11/8</p><p>This is called <code>Generative Poisoning Attack</code> and extensive research seems to has been performed on it.<br>2017/11/8</p><h2 id="Ambiguity-Measure-for-Dropout"><a href="#Ambiguity-Measure-for-Dropout" class="headerlink" title="Ambiguity Measure for Dropout"></a>Ambiguity Measure for Dropout</h2><p>Since increasing ambiguity is a good thing to do in ensembled classifiers, and dropout is essentially a cheap way to ensemble networks, why don’t we add another regularization term in the cost function to increase the ambiguity while dropout?<br>2017/11/1</p><h2 id="Certainty-Measure-for-the-Result"><a href="#Certainty-Measure-for-the-Result" class="headerlink" title="Certainty Measure for the Result"></a>Certainty Measure for the Result</h2><p>According to my observation, it’s weird that a classifier networks always give a clear indication of the result and there is no indication for “Uncertain”. In another word, it seems unlikely for multiple/none of the output nodes to fire at the same time.</p><p>The above may not necessarily be true, but it’s obvious that when a classifier network is given a sample that is totally different from any of the samples in the training set, the result tends to be coming from the weighted combination of the training examples. Will it be possible if we add another class to contain everything else and feed in random noises?</p><p>Unlikely to be useful.<br>2017/11/1</p><h3 id="Recursive-Conv-Net"><a href="#Recursive-Conv-Net" class="headerlink" title="Recursive Conv Net"></a>Recursive Conv Net</h3><p>What would happen is we make a convolution neural network recursive? Will this somehow benefit video generation?</p><p>To be tested.<br>2017/10/27</p><p>It exists…<br>2017/10/30</p><h2 id="Dynamic-Cost-Function"><a href="#Dynamic-Cost-Function" class="headerlink" title="Dynamic Cost Function"></a>Dynamic Cost Function</h2><p>Is it possible if we make the cost function dynamic and change according to the condition so the convergence could be faster? Or is it possible to even use RNN to generate cost function? How would that help? What change would that bring about?<br>To be tested.<br>2017/10/27</p><h3 id="Flip-network"><a href="#Flip-network" class="headerlink" title="Flip network"></a>Flip network</h3><p>According to <a href="https://arstechnica.com/civis/viewtopic.php?f=8&amp;t=785781" target="_blank" rel="external">here</a>, it looks like computers may have different speed between adding and subtracting numbers. If we flip the network so all addition became subtraction and vise versa (Then we might be maximizing the “cost” function), will it be any faster?</p><p>To be tested.<br>2017/10/27</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;These-are-my-own-ideas-of-how-might-the-neural-network-architecture-may-be-improved-as-a-note-reminding-my-further-implementation-of
      
    
    </summary>
    
    
      <category term="Thoughts" scheme="https://d0048.github.io/blog/tags/Thoughts/"/>
    
      <category term="ML" scheme="https://d0048.github.io/blog/tags/ML/"/>
    
      <category term="Problem" scheme="https://d0048.github.io/blog/tags/Problem/"/>
    
  </entry>
  
  <entry>
    <title>to_categorical() missing 1 required positional argument nb_classes caused by tflearn version mismatch</title>
    <link href="https://d0048.github.io/blog/2017/10/25/to-categorical-missing-1-required-positional-argument-nb-classes-caused-by-tflearn-version-mismatch/"/>
    <id>https://d0048.github.io/blog/2017/10/25/to-categorical-missing-1-required-positional-argument-nb-classes-caused-by-tflearn-version-mismatch/</id>
    <published>2017-10-25T12:14:52.000Z</published>
    <updated>2017-10-25T14:00:43.011Z</updated>
    
    <content type="html"><![CDATA[<p><code>TypeError: to_categorical() missing 1 required positional argument: &#39;nb_classes&#39;</code> was encountered while I was trying to run an example program based on it.</p><p>The function <code>to_catagorical()</code> used to require two arguments, where the second is called <code>nb_classes</code> and represents the total class numbers in classification as an integer. </p><p>It’s not until this <a href="https://github.com/tflearn/tflearn/pull/923" target="_blank" rel="external">pr</a> that the second function is no longer needed but the support for the previous usage is dropped and all the examples are updated to adapt to the new usage.</p><p>However, until today, the default version installed directed from pip is not new enough to support this new feature, thus causing a problem. </p><p>To solve it, either try update to the newest version via <code>pip install git+https://github.com/tflearn/tflearn.git</code> or just add the class number. </p><p>2017/10/25</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;code&gt;TypeError: to_categorical() missing 1 required positional argument: &amp;#39;nb_classes&amp;#39;&lt;/code&gt; was encountered while I was trying 
      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="ML" scheme="https://d0048.github.io/blog/tags/ML/"/>
    
      <category term="Python" scheme="https://d0048.github.io/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Note on 1x1 Convolutions</title>
    <link href="https://d0048.github.io/blog/2017/10/25/Note-on-1x1-Convolutions/"/>
    <id>https://d0048.github.io/blog/2017/10/25/Note-on-1x1-Convolutions/</id>
    <published>2017-10-25T07:12:00.000Z</published>
    <updated>2017-10-27T14:30:47.249Z</updated>
    
    <content type="html"><![CDATA[<h2 id="What-does-it-do"><a href="#What-does-it-do" class="headerlink" title="What does it do?"></a>What does it do?</h2><p>This is pretty straight forward, just like normal convolution operation, it converts a piece of data structured <code>[channels, height, width]</code> to <code>[kernal_numbers, same_height, same_width]</code>, using a set of learn-able parameters in the size of <code>[kernel_number, channel_number, weight_for_this_channel]</code>. This operation is usually just a meaningless scaling by a constant unless it is performed across channels, which is usually called a cascade cross channel pooling layer. </p><h2 id="What’s-the-purpose"><a href="#What’s-the-purpose" class="headerlink" title="What’s the purpose?"></a>What’s the purpose?</h2><p>Along all materials read, it seems like this operation is widely used on the following purposes:</p><h3 id="Dimension-augmentation-reduction"><a href="#Dimension-augmentation-reduction" class="headerlink" title="Dimension augmentation/reduction."></a>Dimension augmentation/reduction.</h3><p>This operation is capable of mapping an input of any channel to an output of any channel while preserving the original size of the picture. Do be aware that such operation, especially in dimensionality augmentations, uses large amount of extra parameters, making the network possible more prone to overfitting.</p><h3 id="Rescaling-the-last-layer"><a href="#Rescaling-the-last-layer" class="headerlink" title="Rescaling the last layer."></a>Rescaling the last layer.</h3><p>In the above it’s mentioned that 1x1 convolution could serve as a plain scale of a whole channel, which is usually unnecessary. However, if such need exist, it could be met though this operation.</p><h3 id="Increasing-non-linearity"><a href="#Increasing-non-linearity" class="headerlink" title="Increasing non-linearity."></a>Increasing non-linearity.</h3><p>The fact that it involves a non-linear mapping without drastically altering the input, the non-linearity of the network is increased without using plain fully-connected layers which destroys the relationship between nearby pixels. At the same time, the original size of the input could be preserved.</p><h3 id="The-Network-in-Network-NIN-Structure"><a href="#The-Network-in-Network-NIN-Structure" class="headerlink" title="The (Network in Network)NIN Structure"></a>The (Network in Network)NIN Structure</h3><p>This concept first appeared to me while reading a research paper called <a href="https://arxiv.org/pdf/1312.4400v3.pdf" target="_blank" rel="external">network in network</a>, which seems to be another powerful modification made on CNNs. One of the key aspect this paper adapted is using a multilayer perceptron model to replace the traditional convolution kernel. </p><p>As I wonder how could this model be implemented using higher level api of popular machine learning libraries without modifying the lower level codes, the paper actually stated that such operation of sliding a mini-MLP over a picture across the previous channels is equivalent to cross channel convolution with 1x1 kernels, where a few new 1x1 convolutional layer(CCCP) is appended to a normal convolutional layer to reach the goal.</p><p>The fact that this CCCP operation appending to a normal convolution layers will make a equivalent MLP serves as a sliding convolution kernel, is hard to imagine to be true. It creates confusion in my understanding and it is not until I unroll the whole process so it could be under stood.</p><p>Rather than 2d convolution, using 1d convolution makes things more straight forward while the same rule applies to arbitrary dimensions of convolution.</p><p>Suppose we have an 1d input with 2 channels:<br><br><br><img src="/blog/images/1d_input.png" class="[class1 class2]"><br><br><br>And we perform a normal convolution with one kernel of 2.<br><br><br><img src="/blog/images/1d_input_conv2.png" class="[class1 class2]"><br><br><br>After appending a 1x1(in 1d convolution, just 1) convolution layer with <strong>two</strong> kernels, it looks like:<br><br><br><img src="/blog/images/1d_input_conv2_conv1.png" class="[class1 class2]"><br><br><br>And another 1x1 layer with <strong>two</strong> kernels added:<br><br><br><img src="/blog/images/1d_input_conv2_conv1_conv1.png" class="[class1 class2]"><br><br><br>It’s not hard to see, that this structure is indeed a sliding MLP layer with the input size of the convolution size of the layer appended to, the depth of the number of 1x1 layers appended and the hidden unit numbers of the product of all kernel numbers in the hidden unit, the input numbers and the last layer.</p><h3 id="The-Inception-module"><a href="#The-Inception-module" class="headerlink" title="The Inception module"></a>The Inception module</h3><p>The <a href="https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/" target="_blank" rel="external">inception module</a> is first used in the googlenet architecture, and proved to be really useful.<br><img src="https://raw.githubusercontent.com/iamaaditya/iamaaditya.github.io/master/images/inception_1x1.png" alt=""></p><center>picture retrieved from this <a href="https://wiki.tum.de/display/lfdv/Layers+of+a+Convolutional+Neural+Network" target="_blank" rel="external">website</a></center><p>What this module does is really just adjoining all the output of different size of convolution/pooling together and let the network to choose which to use itself. The pro of this method is that the network is made more resistant to shift in sizes of the target, and the manually adjusting size of the kernels is no longer required–we got most of the possible sizes needed all here.</p><p>As a result, the 1x1 convolution naturally became one of the choices.</p><h2 id="Ideas-for-Future-Research"><a href="#Ideas-for-Future-Research" class="headerlink" title="Ideas for Future Research"></a>Ideas for Future Research</h2><p>As I read, neurons that fired together creates a relationship between each other and every one of them got easier to fire next time given the condition that the related neurons are fired.</p><p>I am thinking that neurons in regular DNNs does not have any knowledge of the state of other neurons in the same layer, thus maybe it would be possible to create such a relation, to somehow create <strong>“logic”</strong> for networks?</p><p>To do so, maybe we need another set of weights in each neuron used to scale the states of other neurons in the same layer and add to the output, somehow like this:<br>$$<br>\vec{y_{n}}=(\mathbf{W_n}^T \times  \vec{y_{n-1}} + \vec{b_n})+\mathbf{W_{new}}^T (\mathbf{W_n}^T \times  \vec{y_{n-1}} + \vec{b_n})<br>$$</p><p><center><strong>If the formula is not displayed correctly, please allow unsecure(HTTP) cross site scripts in your browser.</strong></center><br>The new weight matrix for the new output will be an <code>n*n</code> matrix considering <code>n</code> as the size of the output.</p><p>The detailed implementation is to be researched.</p><p>Edit: Okay… This seems to be just an really stupid way of adding an extra layer, and won’t really make any difference from just adding one at all. (2017/10/27)</p><p>References:<br><a href="http://blog.csdn.net/yiliang_/article/details/60468655" target="_blank" rel="external">http://blog.csdn.net/yiliang_/article/details/60468655</a><br><a href="http://blog.csdn.net/mounty_fsc/article/details/51746111" target="_blank" rel="external">http://blog.csdn.net/mounty_fsc/article/details/51746111</a><br><a href="http://jntsai.blogspot.com/2015/03/paper-summary-network-in-network-deep.html" target="_blank" rel="external">http://jntsai.blogspot.com/2015/03/paper-summary-network-in-network-deep.html</a><br><a href="https://www.zhihu.com/question/64098749" target="_blank" rel="external">https://www.zhihu.com/question/64098749</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;What-does-it-do&quot;&gt;&lt;a href=&quot;#What-does-it-do&quot; class=&quot;headerlink&quot; title=&quot;What does it do?&quot;&gt;&lt;/a&gt;What does it do?&lt;/h2&gt;&lt;p&gt;This is pretty s
      
    
    </summary>
    
    
      <category term="Thoughts" scheme="https://d0048.github.io/blog/tags/Thoughts/"/>
    
      <category term="ML" scheme="https://d0048.github.io/blog/tags/ML/"/>
    
      <category term="Problem" scheme="https://d0048.github.io/blog/tags/Problem/"/>
    
  </entry>
  
  <entry>
    <title>getopt() function on raspery pi</title>
    <link href="https://d0048.github.io/blog/2017/10/23/getopt-function-on-raspery-pi/"/>
    <id>https://d0048.github.io/blog/2017/10/23/getopt-function-on-raspery-pi/</id>
    <published>2017-10-23T08:20:57.000Z</published>
    <updated>2017-10-23T08:25:24.764Z</updated>
    
    <content type="html"><![CDATA[<p>While the <code>getopt()</code> function provided by <code>getopt.h</code> usually returns <code>-1</code> after there are no more arguments. But probably due to certain issues relating to treatment of signs of integers on arm-devices (to be researched), it might return <code>255</code> instead when out of arguments. </p><p>2017/10/23</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;While the &lt;code&gt;getopt()&lt;/code&gt; function provided by &lt;code&gt;getopt.h&lt;/code&gt; usually returns &lt;code&gt;-1&lt;/code&gt; after there are no more argume
      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="C" scheme="https://d0048.github.io/blog/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>The Harmonic Series: How Comes the Divergence</title>
    <link href="https://d0048.github.io/blog/2017/10/17/The-Harmonic-Series-how-comes-the-divergence/"/>
    <id>https://d0048.github.io/blog/2017/10/17/The-Harmonic-Series-how-comes-the-divergence/</id>
    <published>2017-10-17T07:24:42.000Z</published>
    <updated>2017-10-19T14:07:02.701Z</updated>
    
    <content type="html"><![CDATA[<p><strong>IF FORMULAS ARE NOT DISPLAYED CORRECTLY, PLEASE ALLOW UNSECURE(HTTP) CROSS SITE SCRIPTS</strong></p><h2 id="What-are-the-Harmonic-Series"><a href="#What-are-the-Harmonic-Series" class="headerlink" title="What are the Harmonic Series?"></a>What are the Harmonic Series?</h2><p>From Wikipedia, <a href="https://en.wikipedia.org/wiki/Harmonic_series_(mathematics" target="_blank" rel="external">Haronmic Series</a>)</p><blockquote><p>In mathematics, the harmonic series is the divergent infinite series: Its name derives from the concept of overtones, or harmonics in music: the wavelengths of the overtones of a vibrating string are $1/2, 1/3, 1/4$, etc., of the string’s fundamental wavelength. Every term of the series after the first is the harmonic mean of the neighboring terms; the phrase harmonic mean likewise derives from music.</p></blockquote><p>It is basically a series defined like this:<br>$$<br>\sum_{x=1}^{\infty} \frac{1}{x} = \frac{1}{1} + \frac{1}{2} + \frac{1}{3} + \ldots + \frac{1}{\infty}<br>$$<br>and it feels, intuitively, to be converging. However, it’s actually the opposite.</p><h2 id="Why-are-they-diverging"><a href="#Why-are-they-diverging" class="headerlink" title="Why are they diverging?"></a>Why are they diverging?</h2><h3 id="Mathematical-Perspective"><a href="#Mathematical-Perspective" class="headerlink" title="Mathematical Perspective"></a>Mathematical Perspective</h3><p>There are multiple ways to think about it and I find the following the easiest to understand.</p><ol><li>Use $f(x)=\frac{1}{x}$ to regress the series and take an infinite integral:<br>$$<br>\int_{1}^{\infty} f(x) dx = ln(x)<br>$$</li><li>From  the above, if we are taking a finite integral<br>$$<br>ln(x)|_{1}^{\infty} = \infty<br>$$<br>, we can see that the result diverges into infinity.</li></ol><h3 id="Intuitive-Understanding"><a href="#Intuitive-Understanding" class="headerlink" title="Intuitive Understanding"></a>Intuitive Understanding</h3><p>Even if the fact that this series is diverging seems to be mathematically correct, it’s really weird to think about it. Here’s an intuitive way of thinking it.</p><p>For any infinite series, think of is as doing two things together:</p><ul><li>The fact it’s “infinite” is trying to push the sum of it into $\infty$, in another word, divergence.</li><li>The fact that there is an altered term in every new sum added, is trying to push the sum into a finite value by making the newly generated value as small as possible, thus converging.</li></ul><p>And here we have a race between the two forces and by comparing the speed of change the two forces create, we know what’s the result. </p><p>Let’s look at a similar series, that looks a lot alike to our series but actually converges.<br>$$<br>\sum_{x=1}^{\infty} \frac{1}{x^n} = \frac{1}{1^n} + \frac{1}{2^n} + \frac{1}{3^n} + \ldots + \frac{1}{\infty^n}<br>$$<br>The $n$ here is the key and in the Harmonic Series it equals 1. At here, let’s use $n=2$ as an example to create our new series.<br>$$<br>\sum_{x=1}^{\infty} \frac{1}{x^2} = \frac{1}{1^2} + \frac{1}{2^2} + \frac{1}{3^2} + \ldots + \frac{1}{\infty^2}<br>$$<br>Over the course of adding the first term to the $\infty^{st}$ term, looking at the <code>first</code> force, we have a course of:</p><ul><li>1 -&gt; $\infty$ with step length of 1<br>(Adding one more term each iteration)<br>Over the course of adding the first term to the $\infty^{st}$ term, looking at the <code>second</code> force, we have a course of:</li><li>1 -&gt; $\infty$ with step length of $\frac{1}{x^2-(x-1)^2}$, which proved to be $\frac{1}{step_{x-1}+2}$.<br>(Since we are comparing the force of shrinking a value, we can ignore the upper part of the fraction, which makes the step ${step_{x-1}+2}$)<br>For example, the steps between term_1, 2, 3, 4 are 3, 5 and 7.</li></ul><p>This way, we can compare the first force with the second:<br>$$<br>\frac{1}{step_{x-1}+2} &lt; 0<br>$$<br>which means in all steps the speed convergence of this series is larger than the speed of divergence, which makes its overall behavior convergence. </p><p>Let’s look at another example series where <code>n=0.5</code>:<br>$$<br>\sum_{x=1}^{\infty} \frac{1}{x^{0.5}} = \frac{1}{1^{0.5}} + \frac{1}{2^{0.5}} + \frac{1}{3^{0.5}} + \ldots + \frac{1}{\infty^{0.5}}<br>$$<br>(The steps between term_1, 2, 3, 4 are 0.4, 0.3 and 0.25.)<br>And compare the two forces of it:<br>$$<br>\frac{1}{(x^{0.5}-(x-1)^{0.5})^2} &gt; 0<br>$$<br>which means in all steps the speed convergence of this series is smaller than the speed of divergence, which makes its overall behavior divergence. </p><p>Finally, time to deal with our <code>n=1</code> series. We surprisingly found that the speed of divergence is equal to the speed of convergence, which make it lies at the critical area that yet to be defined. </p><p>However, we know that a series have to be either converges or diverges. Think of it like this: a man chasing another man holding a finish line, both of them are at the same speed. The fact that they are chasing each other makes sure the finish line is ahead of the man. This way, the man never gets to the finish line, thus making the final pattern diverges. </p><p>To draw a conclusion:<br>$$<br>\sum_{x=1}^{\infty} \frac{1}{x^n}$$ Converges only if $n&gt;0$</p><h2 id="Extending-the-question"><a href="#Extending-the-question" class="headerlink" title="Extending the question"></a>Extending the question</h2><p>From the above we can tell that the Harmonic Series indeed diverges, but at the critical speed where any tiny change in its speed of divergence/convergence could knock it into another side. What about we try to give it a knock?<br>These problem has already been discussed and the modified series are called Depleted Harmonic Series. </p><p>It’s easy to conclude that changes like pulling away all the recipicals of odd numbers will cause this series to converge. </p><h3 id="Prime-Numbers"><a href="#Prime-Numbers" class="headerlink" title="Prime Numbers?"></a>Prime Numbers?</h3><p>What about pulling away all the recipicals of prime numbers? I heard from a guy on a forum that it still diverges, but I haven’t read any proves. </p><p>This sounds really anti-intuitive because we are excluding an infinite series out of another infinite series(Really? Not proved yet…) where its divergence speed is too low that any reduction will cause it to converge.</p><p>There is yet another possible way of thinking this.</p><p>Due to the unknowns of prime numbers, I will replace them with “any series that gets sparser as it grows”. We know that making a series of all the terms pulled out, this new series actually converges. So we are excluding a finite value out of infinite, which still, equals infinite.</p><p>I can almost immidiently feel that a lot of my logics are really sloppy, please point out if anything is wrong. </p><p>2017/10/17</p><p>Update: ok… my understanding seems to be a bit off. It’s still possible to extract a divergent series out of it to make it still diverges…<br>2017/10/19</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;IF FORMULAS ARE NOT DISPLAYED CORRECTLY, PLEASE ALLOW UNSECURE(HTTP) CROSS SITE SCRIPTS&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;What-are-the-Harmoni
      
    
    </summary>
    
    
      <category term="Math" scheme="https://d0048.github.io/blog/tags/Math/"/>
    
      <category term="Thoughts" scheme="https://d0048.github.io/blog/tags/Thoughts/"/>
    
  </entry>
  
  <entry>
    <title>&quot;libcusolver.so.8.0: cannot open shared object file&quot; error while importing tensorflow</title>
    <link href="https://d0048.github.io/blog/2017/10/16/libcusolver-so-8-0-cannot-open-shared-object-file-error-while-importing-tensorflow/"/>
    <id>https://d0048.github.io/blog/2017/10/16/libcusolver-so-8-0-cannot-open-shared-object-file-error-while-importing-tensorflow/</id>
    <published>2017-10-16T08:18:46.000Z</published>
    <updated>2017-10-16T08:34:30.468Z</updated>
    
    <content type="html"><![CDATA[<p>After installing the gpu version of the tensorflow, I got this error while importing it:</p><pre>>>> import tensorflow as tfTraceback (most recent call last):  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py", line 41, in <module>    from tensorflow.python.pywrap_tensorflow_internal import *  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 28, in <module>    _pywrap_tensorflow_internal = swig_import_helper()  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 24, in swig_import_helper    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)  File "/usr/lib/python3.5/imp.py", line 242, in load_module    return load_dynamic(name, filename, file)  File "/usr/lib/python3.5/imp.py", line 342, in load_dynamic    return _load(spec)ImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory</module></module></pre><p>None of the solutions online, like setting the environmental variables to cuda installation.</p><p>I tried <code>locate libcusolver.so</code> and none of the paths refers to the version I wanted. This is because tensorflow only works with cuda 8.0 but the newest version of cuda is installed. (In my case, 8.0).</p><p>Because I am using ubuntu and installed cuda through ppa, I simply installed cuda 8.0 through <code>sudo apt-get install cuda-8-0</code> and everything worked. </p><p>2017/10/16</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;After installing the gpu version of the tensorflow, I got this error while importing it:&lt;/p&gt;
&lt;pre&gt;
&gt;&gt;&gt; import tensorflow as tf
Traceback 
      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="ML" scheme="https://d0048.github.io/blog/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>Difference Between Weights and Biases: Another way of Looking at Forward Propagation</title>
    <link href="https://d0048.github.io/blog/2017/10/14/Difference-Between-Weights-and-Biases-Another-way-of-Looking-at-Forward-propagation/"/>
    <id>https://d0048.github.io/blog/2017/10/14/Difference-Between-Weights-and-Biases-Another-way-of-Looking-at-Forward-propagation/</id>
    <published>2017-10-14T11:53:39.000Z</published>
    <updated>2017-10-15T12:08:19.805Z</updated>
    
    <content type="html"><![CDATA[<p>================LATEX MATH TEST================:<br>$$<br>\begin{eqnarray}<br>\nabla\times\vec{B} &amp;=&amp; \mu_0\left(\vec{J}+\epsilon_0\frac{\partial E}{\partial t} \right)<br>\end{eqnarray}<br>$$<br><em>IF THE ABOVE IS NOT SHOWING PROPERLY, PLEASE UNBLOCK UNSECURE(HTTP) CROSS SITE SCRIPTS IN YOUR BROWSER</em><br>================LATEX MATH TEST================:</p><h2 id="What-are-Weights-and-Biases"><a href="#What-are-Weights-and-Biases" class="headerlink" title="What are Weights and Biases"></a>What are Weights and Biases</h2><p>Consider the following forward propagation algorithm:<br>$$<br>\vec{y_{n}}=\mathbf{W_n}^T \times  \vec{y_{n-1}} + \vec{b_n}<br>$$<br>where $n$ is the number of the layers, $\vec{y_n}$ is the output of the $n^{th}$ layer, expressed as a $l_n \times 1$ ($l_n$ is the number of neurons of the $n^th$ layer) vector. $\mathbf{W_n}$ is a $l_{n-1} \times l_{n}$ matrix storing all the weights of every connection between layer $n$ and $n-1$, thus needing to be transposed for the sake of the product. $\vec{b_n}$, again, is the biases of the connections between the $n^th$ and $(n-1)^th$ layers, in the shape of $l_n\times1$.</p><p>As one can see, both weights and biases are just changeable and derivable(thus trainable) factors that contributes to the final results.</p><h2 id="Why-do-we-need-both-of-them-and-why-are-Biases-Optional"><a href="#Why-do-we-need-both-of-them-and-why-are-Biases-Optional" class="headerlink" title="Why do we need both of them, and why are Biases Optional?"></a>Why do we need both of them, and why are Biases Optional?</h2><p>Neural network, indeed a better version of the perceptron model, where the output of each neuron(perceptron) owns a linear correlation with the output, rather than simply outputting plain 0/1. (This relation is further more projected to the activation function to make it non-linear, which will be discussed later) </p><p>To create a linear correlation, the easiest way is to scale the input with a certain coefficient $w$, output the scaled input.<br>$$<br>f(x)=w\times x<br>$$</p><p>This model works alright, even with one neuron it could perfectly fit a linear function like $f(x)=m\times x$, and certain non-linear relations could be fit with neurons work in layers. </p><p>However, this new neuron without biases, lack of a significant ability even comparing to perceptron: it always fires regardless the input thus failing to fit functions like $y=mx+b$. It’s impossible to disable the output of a specific neuron on certain threshold value of the input. Even that adding more layers and neurons a lot eases and hides this issue, neural networks without biases are likely to perform a worse job than those with biases.(Consider the total layers/neurons are the same)</p><p>In conclusion, the biases are supplements to the weights to help a network better fit the pattern, which are not necessary but helps the network to perform better. </p><h2 id="Another-way-of-writing-the-Forward-Propagation"><a href="#Another-way-of-writing-the-Forward-Propagation" class="headerlink" title="Another way of writing the Forward Propagation"></a>Another way of writing the Forward Propagation</h2><p>Interestingly, the forward propagation algorithm<br>$$<br>\vec{y_{n}}=\mathbf{W_n}^T \times  \vec{y_{n-1}} + 1 \times \vec{b_n}<br>$$<br>could also be written like this:<br>$$<br>\vec{y_{n}}=<br>\left[ \begin{array}{c}<br>                x, \ 1<br>\end{array} \right]^T<br>\cdot<br>\left[ \begin{array}{c}<br>                \mathbf{W_n},<br>                \ \vec{b_n}<br>\end{array} \right]<br>$$,which is<br>$$<br>\vec{y_{n}} = \vec{y_{new_{n-1}}}^T \times \vec{W_{new}}<br>$$.<br>This is a way of rewriting the equation makes the adjustment by gradient really easy to write.</p><h2 id="How-to-update-them"><a href="#How-to-update-them" class="headerlink" title="How to update them?"></a>How to update them?</h2><p>It’s super easy after the rewrite:<br>$$<br>\vec{W_{new}} =\vec{W_{new}}-\frac{\delta W_{new}}{\delta Error}<br>$$.</p><h2 id="The-Activation-Function"><a href="#The-Activation-Function" class="headerlink" title="The Activation Function"></a>The Activation Function</h2><p>There is one more compoment yet to be mentioned–the Activation Function. It’s basically a function takes the output of a neuron as an input and output whatever value defined as the final output of the neuron.<br>$$<br>\vec{W_{new}} =Activation(\vec{W_{new}}-\frac{\delta W_{new}}{\delta Error})<br>$$<br>There are copious types of them around, but all of them have at least one shared property that there are all <em>Non-linear</em>! </p><p>That’s basically what they are designed for. Activation Functions project output to a non-linear function, thus introducing non-linearity into the model. </p><p>Consider non-linear-seperatable problems like the the XOR problem, giving the network the ability to draw non-linear sperators may help the classification.</p><p>Also, there’s another purpose of the activation function, which is to project a huge input, into the space between -1 and 1, thus making the followed-up calculations easier and faster.<br><br><br>2017/10/15</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;================LATEX MATH TEST================:&lt;br&gt;$$&lt;br&gt;\begin{eqnarray}&lt;br&gt;\nabla\times\vec{B} &amp;amp;=&amp;amp; \mu_0\left(\vec{J}+\epsilon
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://d0048.github.io/blog/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Pass Strings from Python to C/CPP libs</title>
    <link href="https://d0048.github.io/blog/2017/10/12/Pass-Strings-from-Python-to-C-CPP-libs/"/>
    <id>https://d0048.github.io/blog/2017/10/12/Pass-Strings-from-Python-to-C-CPP-libs/</id>
    <published>2017-10-12T00:49:35.000Z</published>
    <updated>2017-10-12T01:18:45.194Z</updated>
    
    <content type="html"><![CDATA[<p>Python strings are stored in the memory in a way smart but not c-friendly. There are two ways python strings could be stored:</p><ol><li><p>Non-specifically-encoded strings are usually stored as wide chars(<code>wchar</code>), where a string <code>&quot;test&quot;</code> in python basically looks like <code>&quot;t\0e\0s\0t\0&quot;</code>. This will mess with any functions in C relying on <code>\0</code> to find the end of a string(char*). </p></li><li><p>Encoded string are stored in the specified codec.</p></li></ol><p>Then, to pass a string object as <code>char*</code> or <code>wchar_t*</code> into native libiaries:</p><ol><li><p><code>import ctypes</code></p></li><li><p>Create the prototype of a function via <code>cdll_name.func_name.argtypes=[type,type,type]</code> to specify the types to pass. Use <code>ctypes.c_char_p</code> or <code>ctypes.c_wchar_p</code> to replace the type to specify the type wanted. A full lists of types could be found <a href="https://docs.python.org/3/library/ctypes.html" target="_blank" rel="external">here</a> under tag <code>16.16.1.4.</code>.</p></li><li><p>Call the function via <code>cdll_name.func_name(type(arg),type(arg)...)</code>. For example: <code>cdll_name.func_name(c_float(3.1),c_char_p(&quot;foo&quot;),c_wchar_p(&quot;bar&quot;))</code></p></li></ol><p>2017/10/12</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Python strings are stored in the memory in a way smart but not c-friendly. There are two ways python strings could be stored:&lt;/p&gt;
&lt;ol&gt;
&lt;l
      
    
    </summary>
    
    
      <category term="Python" scheme="https://d0048.github.io/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Some Thoughts on Deep Neural Networks and Handwritten digit recognition</title>
    <link href="https://d0048.github.io/blog/2017/10/05/Some-Thoughts-on-Deep-Neural-Networks-and-Handwritten-digit-recognition/"/>
    <id>https://d0048.github.io/blog/2017/10/05/Some-Thoughts-on-Deep-Neural-Networks-and-Handwritten-digit-recognition/</id>
    <published>2017-10-05T04:05:29.000Z</published>
    <updated>2017-10-05T04:06:16.823Z</updated>
    
    <content type="html"><![CDATA[<p>Classifying handwritten digits, from the traditional view of machine learning, using the Mnist dataset as an example, indeed classifying points on a (28*28=784) dimensional space into 10 separate classes, which is not necessarily linear seperateable .  </p><p>And the neural network we constructed (the most classical one, with a few fully-connected layers), is no difference than the fancier version of this program:  </p><p>The program above basically works like this:  <a href="https://github.com/D0048/makeyourownneuralnetwork/blob/master/better_detection/train.py" target="_blank" rel="external">https://github.com/D0048/makeyourownneuralnetwork/blob/master/better_detection/train.py</a></p><p>Imagine every picture in the training data set as an 28cm*28cm steal plate, where the darker areas are higher and the whiter areas are lower, with the elevation from 0cm to 255 cm (since the color value ranges from 0~255), or in another way more friendly to calculations, -127.5cm~+127.5cm.  Every steal plate should have an label with it for identification. </p><p>Generated image looks somehow like this (generated from <a href="http://cpetry.github.io/NormalMap-Online/" target="_blank" rel="external">http://cpetry.github.io/NormalMap-Online/</a>): </p><p>Label: 5 </p><p><img src="https://raw.githubusercontent.com/D0048/makeyourownneuralnetwork/master/better_detection/2828_my_own_5.png" width="200" height="200"><br><img src="https://raw.githubusercontent.com/D0048/makeyourownneuralnetwork/master/better_detection/5-3d.png" width="200" height="200"></p><p><br><br>Also, let we create another soft plate made of clay, specifically for the digit ‘5’, where all the initial elevations are 0. </p><p>Then, we collect all the steal plates in the training set labeled “5”, where the total number of them is marked as ‘m’. Smooth each of the steal plates in a scale of 1/m so that all the plates add up to be one plate. For example, the pixel with elevation 125 need to be smoothed into 125/m and the pixel with elevation –123 need to be smoothed into -125/m.  </p><p>After the steal plates are processed, we push it one by one on the clay model we prepared with matrix subtractions. There need to be a total of 10 plates for each digit. </p><p>At last, we pull out an random plate from the training set without reading the label on it, and push it into each of the 10 clay plates we prepare earlier corresponding to each digits, and measure the friction we meet push the steel plate into the clay. The one clay plate with the lowest friction while pushing our test sample inside is supposing to be corresponding to the actual digit represented by the sample.  </p><p>However, these current clay plates-“models” I call them-does not works well at all, considering the fact the a flat clay plate with elevation of –126 will give an virtually zero friction while applied by any sample and the more trainings are applied on a model, the more likely is the model to become flat and blurry and muddy thus making classification under satisfaction.  </p><p>One way to ease the problem is to reverse the rest of the training dataset that does not match the model so that the highest peek now become the lowest valley and apply them to this model again. However, this won’t address the issue from foundation and could somehow make the model more mushy.  </p><p>That’s the reason where the advantages of the neural network comes in, and why I called the neural network “a fancier version”. Basically, a neural network allows us to configure specific weights to each pixel so that the white areas around the actual digit (virtually) no longer contributes to the total friction (called error using former language)  and the black pixels shared by multiple digits, instead of a mess of blurry in our setup, contributes to the total friction in a smarter way, which is more like a black box. By making use of the multi-layer structure, we got a really flexible model that allows certain combination of pixels contributing to the final friction in a unified whole. Also, we can adapt universal methods like gradient descent to select the best weights for each neuron.  </p><p>However, this sounds a little bit strange and anti-intuitive: do we really need to map everything into such a high-dimensional space, in order to just classify 10 different digits? Neural networks seems to be somehow a mimic of brain, but my brain (at least mine) recognizing a digit does not seems to be relying on almost a thousand discrete features of that specific digit, no need to mention that the size of digits in real life could vary vastly according to multiple factors like distance. Do we really need all these features to perform the classification, or can we just first extract less but more pivotal features out the raw image? </p><p>After consideration, I suppose this means “narrower” networks, while deeper might serves as an compromise to it. Also, this means we may use multiple networks to work together in a chain, while some of them trying to extract the feature “smartly” from the data, and some others to deal with the final decision.  </p><p>It’s not until later that I read about the Convolution Neural Network, which is similar to the better neural network in my mind, as what descripted earlier. However, this is still not as expected—I expect a model that works more similar to our neural system, where it should be resistant to scaling (Current CNNs are not capable of doing so. A model called spatial transform network claimed to do so, to be researched) and there should not be such huge training set to reach a good performance. </p><p>Using handwritten digits as an example,  is that possible if we design a network to transform the digits into lines or even to Bézier curve. This way, the scaling problem is resolved. Then,  for ever entity, we can extract far more features rather than just pixels: the total number of close areas, the total interceptions… and so on.  This way, rather than letting the network treating a digit as an ambiguous picture(honestly I can’t even learn how to read digits with some 28*28 pictures), we may actually teach the network, in a more fundamental way, of what is a digit anyway.  </p><p>Recent new idea above, to be tested.  </p><p>Add:</p><p>Now I have somewhat more understanding on CNNs, and find them really powerful. However, it still somehow lack of resistance to size shift of objects. I have the following idea of improvement to be tested:</p><ol><li><p>Give the lower level features to CNNs, (like “does the sample have handle”), which matches our intuitive understanding, but use logic trees and other traditional machine learning methods to make the higher level decisions (like “is the sample a water bottle”), which matches our comprehensional understanding of objects. This may also prevent the network to use irrelevant features limited by the data in the training set. </p></li><li><p>Try different and irregular shapes of reception field, rather than just square. </p></li><li><p>Use another network like RNN to adjust learning rate. </p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Classifying handwritten digits, from the traditional view of machine learning, using the Mnist dataset as an example, indeed classifying 
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://d0048.github.io/blog/tags/Machine-Learning/"/>
    
  </entry>
  
</feed>
