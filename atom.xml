<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Berton&#39;s Workshop</title>
  
  <subtitle>A Record of Thought and Experience</subtitle>
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="https://d0048.github.io/blog/"/>
  <updated>2018-11-21T03:32:15.315Z</updated>
  <id>https://d0048.github.io/blog/</id>
  
  <author>
    <name>D0048</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Comic: 4. Aphorism Space Search</title>
    <link href="https://d0048.github.io/blog/2018/11/21/Comic-4-Aphorism-Space-Search/"/>
    <id>https://d0048.github.io/blog/2018/11/21/Comic-4-Aphorism-Space-Search/</id>
    <published>2018-11-21T03:04:54.000Z</published>
    <updated>2018-11-21T03:32:15.315Z</updated>
    
    <content type="html"><![CDATA[<img src="/blog/2018/11/21/Comic-4-Aphorism-Space-Search/4-1.jpg" alt="[An example aphorism subjects to the search. Credit: (cjfe.org/)]" title="[An example aphorism subjects to the search. Credit: (cjfe.org/)]"><img src="/blog/2018/11/21/Comic-4-Aphorism-Space-Search/4-2.png" alt="[Generalization of the search process.]" title="[Generalization of the search process.]"><p>Especially suitable for high-school essay prompt generation. </p><p>Fan arts inspired by the <a href="https://xkcd.com/" target="_blank" rel="external">XKCD</a> comics. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;img src=&quot;/blog/2018/11/21/Comic-4-Aphorism-Space-Search/4-1.jpg&quot; alt=&quot;[An example aphorism subjects to the search. Credit: (cjfe.org/)]&quot; ti
      
    
    </summary>
    
    
      <category term="Comics" scheme="https://d0048.github.io/blog/tags/Comics/"/>
    
      <category term="Thoughts" scheme="https://d0048.github.io/blog/tags/Thoughts/"/>
    
  </entry>
  
  <entry>
    <title>Comic: 3. Shadow</title>
    <link href="https://d0048.github.io/blog/2018/11/20/Comic-3-Shadow/"/>
    <id>https://d0048.github.io/blog/2018/11/20/Comic-3-Shadow/</id>
    <published>2018-11-20T01:21:23.000Z</published>
    <updated>2018-11-21T03:03:11.894Z</updated>
    
    <content type="html"><![CDATA[<img src="/blog/2018/11/20/Comic-3-Shadow/Shadow.svg.png" alt="[Shadow]" title="[Shadow]"><p>Fan arts inspired by the <a href="https://xkcd.com/" target="_blank" rel="external">XKCD</a> comics. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;img src=&quot;/blog/2018/11/20/Comic-3-Shadow/Shadow.svg.png&quot; alt=&quot;[Shadow]&quot; title=&quot;[Shadow]&quot;&gt;
&lt;p&gt;Fan arts inspired by the &lt;a href=&quot;https://xkcd
      
    
    </summary>
    
    
      <category term="Comics" scheme="https://d0048.github.io/blog/tags/Comics/"/>
    
      <category term="Thoughts" scheme="https://d0048.github.io/blog/tags/Thoughts/"/>
    
  </entry>
  
  <entry>
    <title>Comic: 2. Desktops</title>
    <link href="https://d0048.github.io/blog/2018/10/17/Comic-2-Desktops/"/>
    <id>https://d0048.github.io/blog/2018/10/17/Comic-2-Desktops/</id>
    <published>2018-10-17T14:20:14.000Z</published>
    <updated>2018-11-07T03:22:25.235Z</updated>
    
    <content type="html"><![CDATA[<img src="/blog/images/comic2/2-1.png"><img src="/blog/images/comic2/2-2.png"><p>Fan arts inspired by the <a href="https://xkcd.com/" target="_blank" rel="external">XKCD</a> comics. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;img src=&quot;/blog/images/comic2/2-1.png&quot;&gt;
&lt;img src=&quot;/blog/images/comic2/2-2.png&quot;&gt;
&lt;p&gt;Fan arts inspired by the &lt;a href=&quot;https://xkcd.com/&quot; targ
      
    
    </summary>
    
    
      <category term="Comics" scheme="https://d0048.github.io/blog/tags/Comics/"/>
    
      <category term="Thoughts" scheme="https://d0048.github.io/blog/tags/Thoughts/"/>
    
  </entry>
  
  <entry>
    <title>Comic: 1. Advancement</title>
    <link href="https://d0048.github.io/blog/2018/10/17/Comic-1-Advancement/"/>
    <id>https://d0048.github.io/blog/2018/10/17/Comic-1-Advancement/</id>
    <published>2018-10-17T13:26:12.000Z</published>
    <updated>2018-10-17T14:27:03.314Z</updated>
    
    <content type="html"><![CDATA[<img src="/blog/images/comic1/comic1-1.png"><img src="/blog/images/comic1/comic1-2.png"><p>Fan arts inspired by the <a href="https://xkcd.com/" target="_blank" rel="external">XKCD</a> comics. </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;img src=&quot;/blog/images/comic1/comic1-1.png&quot;&gt;
&lt;img src=&quot;/blog/images/comic1/comic1-2.png&quot;&gt;
&lt;p&gt;Fan arts inspired by the &lt;a href=&quot;https://xkcd.
      
    
    </summary>
    
    
      <category term="Comics" scheme="https://d0048.github.io/blog/tags/Comics/"/>
    
      <category term="Thoughts" scheme="https://d0048.github.io/blog/tags/Thoughts/"/>
    
  </entry>
  
  <entry>
    <title>Note: Neural Turning Machine</title>
    <link href="https://d0048.github.io/blog/2018/08/05/Note-Neural-Turning-Machine/"/>
    <id>https://d0048.github.io/blog/2018/08/05/Note-Neural-Turning-Machine/</id>
    <published>2018-08-05T01:59:58.000Z</published>
    <updated>2018-08-05T02:12:01.644Z</updated>
    
    <content type="html"><![CDATA[<p>Most elegent design I’ve ever seen…</p><h4 id="Mundane-Turing-Machine"><a href="#Mundane-Turing-Machine" class="headerlink" title="Mundane Turing Machine"></a>Mundane Turing Machine</h4><p>A machine in every move, read a symbol from the current position of its <strong>head</strong> on a <strong>tape</strong>, from its <strong>state register</strong> and the symbol read to find the next instruction from its <strong>table</strong>, then based on the instruction, write a symbol with <strong>head</strong>, update its state register, and chooses to move left/right or halt.</p><p>Reference: See <a href="https://en.wikipedia.org/wiki/Turing_machine" target="_blank" rel="external">wikipedia</a>.</p><p><strong>Question:</strong><br>    Wouldn’t turing machine in N-Dimentional Space to be interesting…the head could move in an arbitary direction…</p><hr><h4 id="Overall-Archtecture"><a href="#Overall-Archtecture" class="headerlink" title="Overall Archtecture"></a>Overall Archtecture</h4><img src="/blog/images/neural_turing_machine/ntm_1.png" class="[class1 class2]"><p><strong><em>Difference:</em></strong><br>A neural network is used to replace the mundane <strong>table</strong>, just like what the Deep Q-learning did. <strong>So this is basically a Q-learning model with a differertiable memory bank!</strong></p><hr><h4 id="Memory-Operations"><a href="#Memory-Operations" class="headerlink" title="Memory Operations"></a>Memory Operations</h4><p>In compensation to that, the memory need to be be differentiable to update by gradient descent.</p><p><strong>Define</strong> memory to be a $M\times N$ Matrix $M_t$. It is seemed as a memory with $N$ entries, and each entry have a capacity of $M$.</p><p><strong>Read Operation:</strong><br>The read head emits a softmaxed vector $w_t$ of length $N$, the read $1 \times M$ vector $r_t$ would be<br>$$r_t=\sum_i^N{w_t(i) \times M_t(i)}$$<br>very intuitive.</p><p><strong>Write Operation:</strong><br>Write head emits a softmaxed weighting vector $w_t$ to specify which entries of matrix will be modified.</p><p>For erase, the write head emits a softmaxed erase vector $e_t$, and erase contents by the two weightings:<br>$$\dot M_{t+1}(i) = M_t(i)*(1-w_t(i)e_t(i))$$</p><p>For writing, the write head emmits a addition vector $a_t$ to add to the selected contents:<br>$$M_{t+1}(i)=\dot M_t(i) + w_t(i)a_t(i)$$</p><hr><h4 id="Addressing"><a href="#Addressing" class="headerlink" title="Addressing"></a>Addressing</h4><p>The afore-mentioned weighting vectors are used to operate selected entries, but to select the entries in a diffenertiable way, we need two addressing mechanisms, namely: <strong>Content-based Addressing</strong> and <strong>Location-based Addressing</strong>.</p><p><strong>Overall Addressing Diagram</strong><br><img src="/blog/images/neural_turing_machine/ntm_2.png" class="[class1 class2]"></p><p><strong>Content-based Addressing</strong></p><p>It allows the network to select entries by stating its content, so that it could update it. The head emmits a vector $k_t$ length of $M$, which is compared to each entries to get a content similarity vector $w^c_t$ of length $N$<br>$$w^c_t(i) = \frac{k_t \cdot M(:,i)}{||k_t||\cdot||M(:,i)||} $$<br>. This weighting is then normalized by softmax to further attenuate smaller values and amplify larger values.</p><p><strong>Location-based Addressing</strong></p><p>It allows the network to get the memory of a location without knowing what’s inside.</p><p>First, each head need to provide a scalar interpolation gate $g_t$ to specify which type of addressing is to be used in order to get the current memory:<br>$$w^g_t = g_t w^c_t + (1-g_t) w_{t-1}$$</p><p>In terms of location-based addressing, there are three possible actions, namely to shift: $-1,0,1$ entry to the right, same as a mundane turing machine. This is controlled by a length $3$ softmaxed vector $s_t$ provided by the head. other than softmax, using a shift scalar emitted by the controller as lower bound to simply clip the outputs is also experimented.</p><p>In order to perform the selected shift, a circular convolution is performed on memory $M_t$ by performing that on its index, namely, $w^g_t$, basically rolling the weighting vector $w^g_t$ by $s_t$.<br>$$\dot w_t = \sum_{j=0}^{N-1}w^g_t(j)s_t(i-j)$$</p><p><strong>Sharpening</strong></p><p>Inevitably the rolled weighting vector $w_t^g$ will be blurry due to the diffenertiable nature of the roll. A sharpening operation using a scalar $\mathcal{Y}_t \geqslant 1$ emmitted by the head.<br>$$w_t(i) = \frac{\dot{w_t}(i)^{\mathcal{Y}_t}}{<br>\sum{\dot{w_t}(i)^{\mathcal{Y}_t}}<br>}$$</p><hr><h4 id="Controller-Network"><a href="#Controller-Network" class="headerlink" title="Controller Network"></a>Controller Network</h4><p>Both feed-forward neural network and LSTM are considered to be used as controller. However, due to the fact that currently only one reading/writing head is used, simple operations like multiplying two numbers in memory is made impossible for a feed-forward network. Thus those units of recurrent nature would works better.</p><hr><h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><p><em><a href="https://arxiv.org/abs/1410.5401" target="_blank" rel="external">Neural Turing Machines</a></em> 2014. Alex Graves, Greg Wayne &amp; Ivo Danihelka</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Most elegent design I’ve ever seen…&lt;/p&gt;
&lt;h4 id=&quot;Mundane-Turing-Machine&quot;&gt;&lt;a href=&quot;#Mundane-Turing-Machine&quot; class=&quot;headerlink&quot; title=&quot;Munda
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://d0048.github.io/blog/tags/Machine-Learning/"/>
    
      <category term="Note" scheme="https://d0048.github.io/blog/tags/Note/"/>
    
  </entry>
  
  <entry>
    <title>Note: Cycle GAN</title>
    <link href="https://d0048.github.io/blog/2018/07/29/Note-Cycle-GAN/"/>
    <id>https://d0048.github.io/blog/2018/07/29/Note-Cycle-GAN/</id>
    <published>2018-07-29T06:23:31.000Z</published>
    <updated>2018-08-05T02:04:46.111Z</updated>
    
    <content type="html"><![CDATA[<p>We have set $X=\{x_1,x_2..\}$, $Y=\{y_1,_y2…\}$, where although there do not exist a one-to-one mapping between set $X,Y$, an element $x\in X$ is not distinguishable to elements in $Y$ if not for a certain consistent type of difference. (Eg. with/without snow, zebra/horse…)</p><h4 id="Goal"><a href="#Goal" class="headerlink" title="Goal:"></a>Goal:</h4><p>Find mappings $X \rightarrow X’, Y \rightarrow Y’$ so that $x’\in X’$ is similar enough to $x \in X$ but at the same time indistinguishable from $y\in Y$, and $y’\in Y’$ is similar enough to $y \in Y$ but at the same time indistinguishable from $x\in X$</p><h4 id="Method"><a href="#Method" class="headerlink" title="Method:"></a>Method:</h4><p>Create two generators:<br>$$X’ =Gen_1(X) $$<br>$$Y’ = Gen_2(Y)$$<br>Create three losses:<br>$$L_{discriminator1}=disc(\{y’\},\{y\})$$<br>$$L_{discriminator2}=disc(\{x’\},\{x\})$$<br>$$L_{reconstruction}=||x-x’||_2+||y-y’||_2$$</p><p>And that is all that is necessary.<br>How amazing the design…</p><p>reference:</p><ul><li><em>Unpaired Image-to-Image Translation<br>using Cycle-Consistent Adversarial Networks</em></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;We have set $X=\{x_1,x_2..\}$, $Y=\{y_1,_y2…\}$, where although there do not exist a one-to-one mapping between set $X,Y$, an element $x\
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://d0048.github.io/blog/tags/Machine-Learning/"/>
    
      <category term="Note" scheme="https://d0048.github.io/blog/tags/Note/"/>
    
  </entry>
  
  <entry>
    <title>Note: Deep Learning and the Information Bottleneck Principle</title>
    <link href="https://d0048.github.io/blog/2018/07/22/Note-Deep-Learning-and-the-Information-Bottleneck-Principle/"/>
    <id>https://d0048.github.io/blog/2018/07/22/Note-Deep-Learning-and-the-Information-Bottleneck-Principle/</id>
    <published>2018-07-22T09:25:32.000Z</published>
    <updated>2018-08-05T02:04:41.963Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Method</strong>:<br>For every layer’s output in a densely connected net, calculate its mutual information with the input $X$ and output $Y$.</p><p>Plot the two mutual information of each layer against each other. Observe change as the model is being trained.</p><img src="/blog/images/bottleneck_1.png" class="[class1 class2]"><p>NOTE: This network have exactly 12 bits of input and 2 bits of output.</p><p><strong>Before training</strong>:<br>As a matter of fact, we observe the input layer(green) tells everything about the input itself, and almost everything about the output itself. Since all weights are randomly initialized, as the network goes deeper (further left bottom to the graph), less mutual information are contained against both $X$ and $Y$.</p><p><strong>After training</strong>:<br>The layer outputs contains less information about the input, but more about the output.</p><p><strong>What is important: The Middle</strong>:<br><img src="/blog/images/bottleneck_2.png" class="[class1 class2]"></p><p>Looking at a graph of how each layer moves along the training process, two distinct phases could be found, where in the first phase the layer contains more information of $Y$, where training error decreases. This phase happens fast. The second phase, taking most of the epoches, is a process of eliminating information of $X$ from the layer output. It is viewed as the process of generalization.</p><hr><p>reference:<br><a href="https://www.youtube.com/watch?v=EQTtBRM0sIs" target="_blank" rel="external">https://www.youtube.com/watch?v=EQTtBRM0sIs</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Method&lt;/strong&gt;:&lt;br&gt;For every layer’s output in a densely connected net, calculate its mutual information with the input $X$ and 
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://d0048.github.io/blog/tags/Machine-Learning/"/>
    
      <category term="Note" scheme="https://d0048.github.io/blog/tags/Note/"/>
    
  </entry>
  
  <entry>
    <title>Note: A Neural Algorithm of Artistic Style</title>
    <link href="https://d0048.github.io/blog/2018/07/22/Note-A-Neural-Algorithm-of-Artistic-Style/"/>
    <id>https://d0048.github.io/blog/2018/07/22/Note-A-Neural-Algorithm-of-Artistic-Style/</id>
    <published>2018-07-22T03:38:33.000Z</published>
    <updated>2018-08-05T02:04:15.502Z</updated>
    
    <content type="html"><![CDATA[<p>[A Neural Algorithm of Artistic Style] presented an interesting way to disentangle style of a picture from content of a picture.</p><p>Using the convolution layers of VGG-Network trained for classification, both styles and contents of images could already be well extracted.</p><p><strong>Def 1:<br>Define two image have the same content if they have the same filter response at every layer.</strong><br>In short:<br>$$Loss_{def1}(img_1,img_2)=\sum_{l=0}^n{||F_{img_1}^l-F_{img_2}^l||_2}$$</p><p>where $F_{img}^l$ is the feature maps of $img$ at $l^{th}$ layer.</p><p><strong>Def 2:<br>Define two image have same style if they have the same matrix of correlation among filter responses at every layer</strong></p><ul><li><em>Why define styles like this? Simple to remove spatial properties?</em><br>In short:</li></ul><p>$$Loss_{def2}(img1,img2) = \sum_{n=1}^l{||corr(F_{img_1}^l)- corr(F_{img_2}^l)||_2}$$</p><p><strong>Goal:</strong><br>Find an image $X_{gen}$ that minimize $loss_{def1}(X_{content}, X_{gen})$ using the gradient desent where $X_{content}$ be the image providing layout of the result and $X_{gen}$ be the resultant image starting from white noise.<br>At the same time, $X_{gen}$ need to minimize $loss_{def1}(X_{style}, X_{gen})$, where now $X_{style}$ is the image of a painting of some sort used to provide only style.</p><p>Let $X_{gen}$ be our final generated image.</p><ul><li><em>Why use white noise?</em></li></ul><hr><h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><hr><p><div></div></p><p><div>2015</div><div>    <li><br><a><span>A Neural Algorithm of Artistic Style</span></a><br><br><span>Gatys, L.~A. and Ecker, A.~S. and Bethge, M.</span><br><br><span></span><br><span><br><span>2015</span></span><br><br><br><a><br>    [bibtex]<br></a><br><br><br><br></li></div></p><h2 id=""><a href="#" class="headerlink" title=""></a></h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[A Neural Algorithm of Artistic Style] presented an interesting way to disentangle style of a picture from content of a picture.&lt;/p&gt;
&lt;p&gt;U
      
    
    </summary>
    
    
      <category term="Thoughts" scheme="https://d0048.github.io/blog/tags/Thoughts/"/>
    
      <category term="Machine Learning" scheme="https://d0048.github.io/blog/tags/Machine-Learning/"/>
    
      <category term="Note" scheme="https://d0048.github.io/blog/tags/Note/"/>
    
  </entry>
  
  <entry>
    <title>Fix Xlib:  extension GLX missing on display :8 error running Gui programs</title>
    <link href="https://d0048.github.io/blog/2017/12/25/Fix-Xlib-extension-GLX-missing-on-display-8-error-running-Gui-programs/"/>
    <id>https://d0048.github.io/blog/2017/12/25/Fix-Xlib-extension-GLX-missing-on-display-8-error-running-Gui-programs/</id>
    <published>2017-12-25T03:53:57.000Z</published>
    <updated>2018-01-10T07:53:31.084Z</updated>
    
    <content type="html"><![CDATA[<p>After installing both Bumblebee and Nvdia Prime like <a href="https://d0048.github.io/blog/2017/12/10/Ubuntu-16-04-ultimate-dual-graphic-card-solution-with-newest-nvidia-proprietary-drivers-switchable-without-logout/">this</a>, an error of:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Xlib:  extension <span class="string">"GLX"</span> missing on display <span class="string">":8"</span>.</div></pre></td></tr></table></figure></p><p>is got when attempting to run an gui program. </p><p>The most effective solution found is to follow this solution <a href="https://github.com/Bumblebee-Project/Bumblebee/issues/759" target="_blank" rel="external">here</a> given by sapjunior, but with slight modification. </p><p>Here’s the solution worked for me:<br><strong><em>Still all the driver version numbers need to be replaced with yours!</em></strong></p><ol><li><p>Add the following to <code>/etc/modprobe.d/bumblebee.conf</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">alias</span> nvidia-drm nvidia_364_drm</div><div class="line"><span class="built_in">alias</span> nvidia-uvm nvidia_364_uvm</div><div class="line"><span class="built_in">alias</span> nvidia-modeset nvidia_364_modeset</div><div class="line">remove nvidia rmmod nvidia-drm nvidia-modeset nvidia-uvm nvidia</div></pre></td></tr></table></figure></li><li><p>Perform these two command and record the configuration file names currently used.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo update-alternatives --config x86_64-linux-gnu_gl_conf</div><div class="line">sudo update-alternatives --config i386-linux-gnu_gl_conf</div></pre></td></tr></table></figure></li><li><p>Make sure the <code>x86_64</code> config contains all of the following</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">/usr/lib/x86_64-linux-gnu/mesa</div><div class="line">/usr/lib/x86_64-linux-gnu/mesa-egl</div><div class="line">/usr/lib/i386-linux-gnu/mesa</div><div class="line">/usr/lib/i386-linux-gnu/mesa-egl</div><div class="line">/usr/lib/nvidia-387</div><div class="line">/usr/lib32/nvidia-387</div></pre></td></tr></table></figure><p>and the i386 config contains all of the following:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">/usr/lib/i386-linux-gnu/mesa</div><div class="line">/usr/lib32/nvidia-387</div></pre></td></tr></table></figure></li><li><p>Refresh shared libiary status with <code>sudo ldconfig</code>. (Maybe reboot just in case)</p></li></ol><p>2018/1/10</p><!---1. Perform the following and choose the one with `mesa` inside. <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo update-alternatives --config x86_64-linux-gnu_gl_conf</div><div class="line">sudo update-alternatives --config x86_64-linux-gnu_egl_conf</div><div class="line">sudo update-alternatives --config i386-linux-gnu_gl_conf</div><div class="line">sudo update-alternatives --config i386-linux-gnu_egl_conf</div></pre></td></tr></table></figure><ol><li>Edit: The following still seems to be necessary…<br>add /usr/lib/nvidia-364 to =&gt; /usr/lib/x86_64-linux-gnu/mesa/ld.so.conf<br>add /usr/lib32/nvidia-364 to =&gt; /usr/lib/i386-linux-gnu/mesa/ld.so.conf</li></ol><ol><li>Refresh shared libiary status with <code>sudo ldconfig</code>.</li></ol><p>2017/12/25</p><p>Add: seems like this setting will be reset after reboot… Just add the following command s on boot:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sleep 5 <span class="comment">#Some delay seems to be necessary</span></div><div class="line">sudo update-alternatives --<span class="built_in">set</span> x86_64-linux-gnu_gl_conf /usr/lib/x86_64-linux-gnu/mesa/ld.so.conf</div><div class="line">sudo update-alternatives --<span class="built_in">set</span> x86_64-linux-gnu_egl_conf /usr/lib/x86_64-linux-gnu/mesa-egl/ld.so.conf</div><div class="line">sudo update-alternatives --<span class="built_in">set</span> i386-linux-gnu_gl_conf /usr/lib/i386-linux-gnu/mesa/ld.so.conf</div><div class="line">sudo ldconfig</div></pre></td></tr></table></figure></p><p>–&gt;</p>-->]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;After installing both Bumblebee and Nvdia Prime like &lt;a href=&quot;https://d0048.github.io/blog/2017/12/10/Ubuntu-16-04-ultimate-dual-graphic-
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu 16.04 ultimate dual graphic card solution with newest nvidia proprietary drivers switchable without logout</title>
    <link href="https://d0048.github.io/blog/2017/12/10/Ubuntu-16-04-ultimate-dual-graphic-card-solution-with-newest-nvidia-proprietary-drivers-switchable-without-logout/"/>
    <id>https://d0048.github.io/blog/2017/12/10/Ubuntu-16-04-ultimate-dual-graphic-card-solution-with-newest-nvidia-proprietary-drivers-switchable-without-logout/</id>
    <published>2017-12-10T14:47:15.000Z</published>
    <updated>2017-12-25T04:06:54.236Z</updated>
    
    <content type="html"><![CDATA[<p>Finally I got it working. Using both nvidia-prime and bumblebee at the same time to allow switches between the two graphic cards (intel and nvidia) in both per-application-without-logout and whole-system-with-logout manner. My cuda also stays working at both mode. </p><p>The following are the steps. </p><ol><li><p>Add newest nvidia-driver ppa: <code>sudo add-apt-repository ppa:graphics-drivers/ppa;sudo apt update</code>.</p></li><li><p>Install the proprietary driver(in my case, 384, larger index should means newer) and nvidia-prime: <code>sudo apt install nvidia-384 nvidia-prime</code>.</p></li><li><p>[optional] Add prime-indicator ppa and install <code>sudo add-apt-repository ppa:nilarimogard/webupd8;sudo apt update;sudo apt install prime-indicator-plus;</code></p></li><li><p>Reboot and the graphic cards should be able to be switchable with the indicator or x-org-setting from the dash menu. But it requires a reboot to perform the switch. If that’s not satisfactory and the user want more flexible control, proceed. If not, stop here. </p></li><li><p>Install bbswitch and bumblebee: <code>sudo apt install bbswitch-dkms bumblebee bumblebee-nvidia</code>.</p></li><li><p>Configure bumblebee to work. </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo gpasswd -a <span class="variable">$USER</span> bumblebee</div><div class="line">sudo systemctl <span class="built_in">enable</span> bumblebeed</div></pre></td></tr></table></figure></li></ol><p>open the config file <code>sudo gedit /etc/bumblebee/bumblebee.conf</code> and edit:<br><code>Driver=</code> $\rightarrow$ <code>Driver=nvidia</code><br><strong>Remember to replace all <code>384</code> to your driver index</strong><br><code>KernelDriver=nvidia-384</code><br><code>LibraryPath=/usr/lib/nvidia-384:/usr/lib32/nvidia-384</code><br><code>XorgModulePath=/usr/lib/nvidia-384/xorg,/usr/lib/xorg/modules</code></p><p>open the config file <code>/etc/modprobe.d/bumblebee.conf</code> and add:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">blacklist nvidia-384</div><div class="line">blacklist nvidia-384-updates</div><div class="line">blacklist nvidia-experimental-384</div></pre></td></tr></table></figure></p><ol><li><p>Reboot and prey.</p></li><li><p>If everything goes right, you should be able to use <code>optirun COMMAND</code> to run an application using the nvidia graphic card even if you disabled the card and set to use the intel graphic card in the nvidia-prime setting. </p></li><li><p>Try <code>optirun COMMAND</code> or <code>primusrun COMMAND</code> and see if everything works. It’s said that the former is of better performances but its actually 3 times slower on my machine.</p></li><li><p>Remember to turn off the power of nvidia GPU after using it through the indicator to save power.</p></li></ol><p>2017/12/10</p><p><strong>Add: After updating to nvidia-387, except changing the config files, a manual power on through prime indicator seems to be necessary everytime before use. </strong></p><p>Add: To solve the error: <code>Xlib:  extension &quot;GLX&quot; missing on display &quot;:8&quot;.</code>, see <a href="https://d0048.github.io/blog/2017/12/25/Fix-Xlib-extension-GLX-missing-on-display-8-error-running-Gui-programs/">here</a>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Finally I got it working. Using both nvidia-prime and bumblebee at the same time to allow switches between the two graphic cards (intel a
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>Solution to AttributeError ProgressBar object has no attribute finished error using ubuntu-make</title>
    <link href="https://d0048.github.io/blog/2017/11/30/AttributeError-ProgressBar-object-has-no-attribute-finished-error-using-ubuntu-make/"/>
    <id>https://d0048.github.io/blog/2017/11/30/AttributeError-ProgressBar-object-has-no-attribute-finished-error-using-ubuntu-make/</id>
    <published>2017-11-30T11:12:31.000Z</published>
    <updated>2017-11-30T11:23:24.501Z</updated>
    
    <content type="html"><![CDATA[<p>It seems like the umake version contained in the ubuntu 16.04 ppa <code>ppa:ubuntu-desktop/ubuntu-make</code> breaks due to a change in the API of the python <code>ProgressBar</code> module…</p><p>The error log looks like this: </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">N/A% (0 of 100) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--Downloading and installing requirements</div><div class="line">ERROR: Unhandled exception</div><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"/usr/lib/python3/dist-packages/umake/tools.py"</span>, line 158, <span class="keyword">in</span> wrapper</div><div class="line">    <span class="keyword">function</span>(*args, **kwargs)</div><div class="line">  File <span class="string">"/usr/lib/python3/dist-packages/umake/frameworks/baseinstaller.py"</span>, line 288, <span class="keyword">in</span> get_progress</div><div class="line">    <span class="keyword">if</span> not self.pbar.finished:  <span class="comment"># drawing is delayed, so ensure we are not done first</span></div><div class="line">AttributeError: <span class="string">'ProgressBar'</span> object has no attribute <span class="string">'finished'</span></div><div class="line">ERROR: Unhandled exception</div><div class="line">Traceback (most recent call last):</div><div class="line">  File <span class="string">"/usr/lib/python3/dist-packages/umake/tools.py"</span>, line 158, <span class="keyword">in</span> wrapper</div><div class="line">    <span class="keyword">function</span>(*args, **kwargs)</div><div class="line">  File <span class="string">"/usr/lib/python3/dist-packages/umake/frameworks/baseinstaller.py"</span>, line 288, <span class="keyword">in</span> get_progress</div><div class="line">    <span class="keyword">if</span> not self.pbar.finished:  <span class="comment"># drawing is delayed, so ensure we are not done first</span></div><div class="line">AttributeError: <span class="string">'ProgressBar'</span> object has no attribute <span class="string">'finished'</span></div></pre></td></tr></table></figure><p>However, I failed to find a file corresponding to <code>File &quot;/usr/lib/python3/dist-packages/umake/frameworks/baseinstaller.py&quot;</code> in the github repo, thus failing to start an pr/issue. </p><p>For those who encounter similar issue, here’s the quick fix…</p><ol><li><p>Use your favorite editor and root access to open the file <code>/usr/lib/python3/dist-packages/umake/frameworks/baseinstaller.py</code>, e.g <code>sudo gedit /usr/lib/python3/dist-packages/umake/frameworks/baseinstaller.py</code>. </p></li><li><p>Go to line 288.</p></li><li><p>Change the line <code>if not self.pbar.finished:  # drawing is delayed, so ensure we are not done first</code> to <code>if True:</code>, save and quit. </p></li><li><p>The progress bar may looks kinda broken after the fix, but will have no interruption to any installation…</p></li></ol><p><code>2017/11/30</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;It seems like the umake version contained in the ubuntu 16.04 ppa &lt;code&gt;ppa:ubuntu-desktop/ubuntu-make&lt;/code&gt; breaks due to a change in t
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>Setting up the FRC development environment on ubuntu 16.04</title>
    <link href="https://d0048.github.io/blog/2017/11/30/Setting-up-the-FRC-development-environment-on-ubuntu-16-04/"/>
    <id>https://d0048.github.io/blog/2017/11/30/Setting-up-the-FRC-development-environment-on-ubuntu-16-04/</id>
    <published>2017-11-30T01:21:42.000Z</published>
    <updated>2018-01-17T14:52:21.428Z</updated>
    
    <content type="html"><![CDATA[<p>This is a record setting up the FRC development environment for C++/Java for the comp in 2018. </p><ol><li><p>Normally setting up the system, install anything one may need like <code>git/svn/browser</code>… and so on. </p></li><li><p>Add FRC cmake tool ppa: <code>sudo add-apt-repository ppa:wpilib/toolchain-beta</code>, download package list: <code>sudo apt update</code>, download toolchains <code>sudo apt install frc-toolchain</code>.</p></li><li><p>Download eclipse <code>sudo apt install eclipse</code>.</p></li><li><p>Download C++ support for eclipse <code>sudo apt install sudo apt install eclipse-cdt*</code> if using bash(default). If using zsh, use <code>sudo apt install eclipse-cdt\*</code>.</p></li><li><p>Install the IDE/editor wanted. In my case: </p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sudo add-apt-repository ppa:ubuntu-desktop/ubuntu-make;</div><div class="line">sudo add-apt-repository ppa:jonathonf/vim;</div><div class="line">sudo apt update;</div><div class="line">sudo apt install ubuntu-make vim;</div><div class="line">umake ide eclipse</div></pre></td></tr></table></figure><p><strong>If umake went wrong(which suppose to in my current version), refer <a href="https://d0048.github.io/blog/2017/11/30/AttributeError-ProgressBar-object-has-no-attribute-finished-error-using-ubuntu-make/">this link</a> to fix a bug of umake</strong></p><ol><li><p>Open eclipse and install the CDT plugin(for cpp development), Lib for FRC, and vim mode.<br><code>help-&gt;install new software-&gt;add-&gt;Enter &quot;http://download.eclipse.org/tools/cdt/releases/9.3&quot; for eclipse oxygen -&gt; select all -&gt; install...</code><br><code>help-&gt;install new software-&gt;add-&gt;Enter &quot; http://vrapper.sourceforge.net/update-site/stable&quot; for eclipse oxygen -&gt; select all -&gt; install...</code><br><code>help-&gt;install new software-&gt;add-&gt;Enter &quot; http://first.wpi.edu/FRC/roborio/release/eclipse/&quot; for eclipse oxygen -&gt; select all -&gt; install...</code></p></li><li><p>Install <code>LabView</code> started with downloading the standard linux ISO at the official website of NI. </p></li><li><p>Unluckily, the official one only support redhat series thus our debian series will not fit. We need to convert those <code>.rpm</code> packages inside the ISO into <code>.deb</code> so we can install and manage them with our native package manager. (Although one can manually unpack and install them, it would be a great pain…)</p></li><li><p>Start by installing tools: <code>sudo apt install fakeroot alien</code>.</p></li><li><p>Then extract or mount the file inside the ISO and copy everything in the root dir (inside the i386 folder for 32 bit installations) to a any working directory. </p></li><li><p>Run <code>fakeroot alien -k --script ./*.rpm</code> after entering the working directory chosen. </p></li><li><p>Wait till finish, and <code>sudo dpkg -i *.deb</code>. And LabView should be installed. </p></li><li><p>Now we need to install the FRC Plugin for LabView. </p></li><li><p>Unfortunately, the current version of FRC Plugin does not support Linux OS…Tooooooooooo bad.</p></li><li><p>Anyway, download the newest version of the zip file that could be found <a href="http://first.wpi.edu/FRC/roborio/maven/release/edu/wpi/first/wpilib/simulation/simulation/" target="_blank" rel="external">here</a>; then unpack it into <code>~/wpilib/simulation</code>. *(If not exist, create one.)</p></li><li><p>Manually install the files:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">vim sim_ds.desktop frcsim.desktop <span class="comment"># Replace "/usr/bin" with "~/.local/bin"</span></div><div class="line"><span class="built_in">cd</span> ~/wpilib/simulation/</div><div class="line">ln -s frcsim ~/.<span class="built_in">local</span>/bin/</div><div class="line">ln -s sim_ds ~/.<span class="built_in">local</span>/bin/sim_ds</div><div class="line">cp frcsim.desktop sim_ds.desktop ~/.<span class="built_in">local</span>/share/applications/</div></pre></td></tr></table></figure></li><li><p>Build simulation for wpilib:</p><pre><code class="bash"></code></pre></li></ol><p><code>2017/12/4</code> TO BE CONTINUED</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This is a record setting up the FRC development environment for C++/Java for the comp in 2018. &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Normally setting up the s
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="FRC" scheme="https://d0048.github.io/blog/tags/FRC/"/>
    
  </entry>
  
  <entry>
    <title>Make touchegg work on ubuntu unity/gnome desktops</title>
    <link href="https://d0048.github.io/blog/2017/11/23/Make-touchegg-work-on-ubuntu-unity-gnome-desktops/"/>
    <id>https://d0048.github.io/blog/2017/11/23/Make-touchegg-work-on-ubuntu-unity-gnome-desktops/</id>
    <published>2017-11-23T03:23:07.000Z</published>
    <updated>2017-11-23T03:28:31.290Z</updated>
    
    <content type="html"><![CDATA[<p>It seems like the unity DE somehow blocks the mouse gesture for itself, thus most of the other multi-touch recognizers can not catch the events. </p><p>To disable this, the unity multi-touch support need to be completely disabled:</p><ol><li>Install <code>dconf-editor</code>, using <code>apt install dconf-editor -y</code>.</li><li>Launch <code>dconf-editor</code> via command line.</li><li>Go to <code>com-&gt;canonical-&gt;unity-&gt;gestures</code> and disable everything inside.</li></ol><p>Now tools like toughegg could catch touchpad events as normal. </p><p><code>2017/11/23</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;It seems like the unity DE somehow blocks the mouse gesture for itself, thus most of the other multi-touch recognizers can not catch the 
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>A Brief Summary of the Godel&#39;s Incompleteness Theorems</title>
    <link href="https://d0048.github.io/blog/2017/11/21/A-Brief-Summary-of-the-Godel-s-Incompleteness-Theorems/"/>
    <id>https://d0048.github.io/blog/2017/11/21/A-Brief-Summary-of-the-Godel-s-Incompleteness-Theorems/</id>
    <published>2017-11-21T09:00:50.000Z</published>
    <updated>2017-11-21T09:31:20.094Z</updated>
    
    <content type="html"><![CDATA[<p>$\forall Axiomatic_System \\=&gt;  (!Completeness) OR (!Consistency)$</p><blockquote><p>There are inherent limitations of every formal axiomatic system containing <strong>basic arithmetic</strong>.</p></blockquote><p><br></p><h4 id="Completeness"><a href="#Completeness" class="headerlink" title="Completeness:"></a><strong>Completeness</strong>:</h4><blockquote><p>for any statement in the axioms’ language, that statement or its negation is provable from the axioms</p></blockquote><h4 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency:"></a><strong>Consistency</strong>:</h4><blockquote><p>there is no statement such that both the statement and its negation are provable from the axioms</p></blockquote><h4 id="First-incompleteness-theorem"><a href="#First-incompleteness-theorem" class="headerlink" title="First incompleteness theorem:"></a><strong>First incompleteness theorem</strong>:</h4><p>The conclusion is: there will always be elements whether </p><ul><li><em>both belong and don’t belong to a set</em> =&gt; Breaking <em>consistancy</em>. </li><li><em>can not be classified</em> =&gt; Breaking the <em>completeness</em>.</li></ul><blockquote><p>Any consistent formal system F within which a certain amount of elementary arithmetic can be carried out is incomplete; i.e., there are statements of the language of F which can neither be proved nor disproved in F.</p></blockquote><p><strong>Gödel sentence</strong> =&gt; The above mentioned statements that either unprovable or could be proved to be both true/false.</p><ul><li>The Gödel sentence is designed to refer, indirectly, to itself. </li><li>Define itself as something that’s not itself in itself. </li><li><p>Construction:</p><ul><li>$T \leftrightarrow \lnot True(T)$</li></ul></li><li><p>With inconsistency $B\lor\lnot B$, we can prove anything:</p><ul><li>$B\lor\lnot B$</li><li>$def: \lnot A \rightarrow (B \lor \lnot B)$</li><li>$\lnot(B\lor \neg B)\rightarrow \neg \neg A$</li><li>$B \land \neg B \rightarrow A$</li><li>$B \land \neg B$</li></ul></li></ul><h4 id="Second-incompleteness-theorem"><a href="#Second-incompleteness-theorem" class="headerlink" title="Second incompleteness theorem:"></a><strong>Second incompleteness theorem</strong>:</h4><h4 id="Solution"><a href="#Solution" class="headerlink" title="Solution:"></a><strong>Solution</strong>:</h4><p><a href="https://plato.stanford.edu/entries/type-theory/" target="_blank" rel="external">The Type Theory</a>, Where operators are put into types and they can not be used to describle those that are in the same type, including themselves. This way, the <em>Russell Paradox</em>, using an operation in a statement pointing to the statment itself as a Godel sentence, is simply invalid. </p><p>Reference: <a href="https://en.wikipedia.org/wiki/Gödel&#39;s_incompleteness_theorems" target="_blank" rel="external">Wikipedia</a>, <a href="https://www.zhihu.com/question/27528796" target="_blank" rel="external">Zhihu1</a>, <a href="https://www.zhihu.com/question/20511488/answer/133390930" target="_blank" rel="external">Zhihu2</a></p><p>2017/11/21</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;$\forall Axiomatic_System \\=&amp;gt;  (!Completeness) OR (!Consistency)$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There are inherent limitations of every formal 
      
    
    </summary>
    
    
      <category term="Math" scheme="https://d0048.github.io/blog/tags/Math/"/>
    
  </entry>
  
  <entry>
    <title>Preventing CPU/IO Intensive Programs Blocking Linux Gui</title>
    <link href="https://d0048.github.io/blog/2017/11/19/Preventing-CPU-IO-Intensive-Programs-Blocking-Linux-Gui/"/>
    <id>https://d0048.github.io/blog/2017/11/19/Preventing-CPU-IO-Intensive-Programs-Blocking-Linux-Gui/</id>
    <published>2017-11-19T06:05:40.000Z</published>
    <updated>2017-11-19T06:31:20.710Z</updated>
    
    <content type="html"><![CDATA[<h3 id="What-for"><a href="#What-for" class="headerlink" title="What for?"></a>What for?</h3><p>The fact that the linux kernel does NOT come with a GUI and the GUIs used are third  party components, their default priority levels (or nice level, which is user-space name for priority.) are the same as any other user space programs. This may cause the GUI to freeze when performing CPU/IO intensive jobs since they all run at the same priority level. </p><h3 id="What’s-nice-value-priority"><a href="#What’s-nice-value-priority" class="headerlink" title="What’s nice value/priority?"></a>What’s nice value/priority?</h3><p>To prevent that, we need to change the nice level, where the priority of a process equals <code>NICE_VALUE+20</code>. That’s said, higher priority level, same as higher nice level, creates a less prior job. </p><p>Usually run a program with <code>nice -n $NI_VALUE $COMMAND</code> starts a program with a given nice value. <code>renice -n NI_VALUE $PID</code> changes the priority level of a process with the given pid. (multiple pid could be given to change them all) </p><p>Sub-processes owns the same nice level with their parents.</p><h3 id="What-about-IO"><a href="#What-about-IO" class="headerlink" title="What about IO?"></a>What about IO?</h3><p>The above works for CPU priority only. For IO control, the default priority will be <code>cpu_priority / 5</code> and one can always change that using <code>ionice</code>.</p><h3 id="To-make-them-automatic"><a href="#To-make-them-automatic" class="headerlink" title="To make them automatic"></a>To make them automatic</h3><p>I recommend putting the pivotal GUI components into startup script or <code>crontab -e</code>(cron needed to be installed) like this:</p><pre>#"sudo crontab -e" to input* * * * * renice -n -4 -p $(pidof vivaldi-bin)* * * * * renice -n -8 -p $(pidof nautilus)* * * * * renice -n -8 -p $(pidof Xorg)* * * * * renice -n -8 -p $(pidof compiz)</pre><p>2017/11/19</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;What-for&quot;&gt;&lt;a href=&quot;#What-for&quot; class=&quot;headerlink&quot; title=&quot;What for?&quot;&gt;&lt;/a&gt;What for?&lt;/h3&gt;&lt;p&gt;The fact that the linux kernel does NOT come
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>|failed to start docker application container engine| error after upgrade on ubuntu</title>
    <link href="https://d0048.github.io/blog/2017/11/16/failed-to-start-docker-application-container-engine-error-after-upgrade-on-ubuntu/"/>
    <id>https://d0048.github.io/blog/2017/11/16/failed-to-start-docker-application-container-engine-error-after-upgrade-on-ubuntu/</id>
    <published>2017-11-16T02:47:52.000Z</published>
    <updated>2017-11-16T02:50:30.528Z</updated>
    
    <content type="html"><![CDATA[<p>Referring to this (issue)[<a href="https://github.com/moby/moby/issues/29179" target="_blank" rel="external">https://github.com/moby/moby/issues/29179</a>], added <code>--storage-driver=overlay</code> at the end of the line defining <code>ExecStart</code> and tried <code>sudo systemctl daemon-reload;sudo systemctl daemon-reload ;sudo apt -f install</code>.</p><p>Worked for me.<br>2017/11/16</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Referring to this (issue)[&lt;a href=&quot;https://github.com/moby/moby/issues/29179&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/moby/moby
      
    
    </summary>
    
    
      <category term="Linux" scheme="https://d0048.github.io/blog/tags/Linux/"/>
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>Rejailbreak Kindle PaperWhite3 After Automatic Upgrade to 5.9.2/5.9.3/5.9.4/5.9.5/5.9.6/5.9.7</title>
    <link href="https://d0048.github.io/blog/2017/11/15/Rejailbreak-Kindle-PaperWhite3-After-Automatic-Upgrade-to-5-9-2/"/>
    <id>https://d0048.github.io/blog/2017/11/15/Rejailbreak-Kindle-PaperWhite3-After-Automatic-Upgrade-to-5-9-2/</id>
    <published>2017-11-15T03:08:09.000Z</published>
    <updated>2018-08-25T13:47:53.229Z</updated>
    
    <content type="html"><![CDATA[<p>(Tested to be working with later versions)<br>My kindle pw3 seems to be automatically updated from 5.9.1 to 5.9.2 and I am unable to run KUAL anymore. To fix this, the following is performed and I am not sure whether any of these steps are necessary.But I did get everything back without losing any data/plugins.</p><ol><li><p>Applied a jailbreak hotfix <code>Update_jailbreak_hotfix_1.14_nomax_install.bin</code>. File found at <a href="https://bookfere.com/post/576.html" target="_blank" rel="external">here</a>. Patched by copying it to the root fs mounted on computer and manually select “update” in menu.</p></li><li><p>Applied <code>Update_KUALBooklet_v2.7_install.bin</code> and <code>update_kpvbooklet_0.6.6_install.bin</code>. File found at <a href="https://bookfere.com/post/311.html" target="_blank" rel="external">here</a> and <a href="https://github.com/koreader/kpvbooklet/releases" target="_blank" rel="external">here</a>. Patched by copying it to <code>/mrpackages</code> and searching <code>;log mrpi</code>. </p></li></ol><p>This process is recorded hoping to be helpful. Do notice that your devices may not work just as mine and I will not be responsible for any following consequences happened to your device.</p><p>2017/11/15</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;(Tested to be working with later versions)&lt;br&gt;My kindle pw3 seems to be automatically updated from 5.9.1 to 5.9.2 and I am unable to run 
      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="Kindle" scheme="https://d0048.github.io/blog/tags/Kindle/"/>
    
  </entry>
  
  <entry>
    <title>Use System Memory Together with Graphic Memory in TensorFlow</title>
    <link href="https://d0048.github.io/blog/2017/11/08/Use-System-Memory-Together-with-Graphic-Memory-in-TensorFlow/"/>
    <id>https://d0048.github.io/blog/2017/11/08/Use-System-Memory-Together-with-Graphic-Memory-in-TensorFlow/</id>
    <published>2017-11-08T02:52:25.000Z</published>
    <updated>2018-08-05T02:06:29.971Z</updated>
    
    <content type="html"><![CDATA[<p>The default options in tensorflow uses graphic memories only and all the tensors are allocated on boot. These are relatively faster, but are also disaster when using a graphic card with lower memories, and I am always getting OOMs from my model.</p><p>There are two ways to ease the issue, which are to enable tensorflow to utilize system memory and disable tensorflow to allocated all memory blocks on boot. </p><pre>    config = tf.ConfigProto()    config.gpu_options.allow_growth = True    config.gpu_options.per_process_gpu_memory_fraction = 0.9    with tf.Session(config=config) as sess:        code to run...        pass</pre><p>The attribute <code>config.gpu_options.per_process_gpu_memory_fraction</code> specifies the fraction of maximum graphic memory to use before using system memory.</p><p>2017/11/8</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;The default options in tensorflow uses graphic memories only and all the tensors are allocated on boot. These are relatively faster, but 
      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="Machine Learning" scheme="https://d0048.github.io/blog/tags/Machine-Learning/"/>
    
      <category term="Python" scheme="https://d0048.github.io/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Prevent Blocking When Using PyPlot</title>
    <link href="https://d0048.github.io/blog/2017/11/02/Prevent-Blocking-When-Using-PyPlot/"/>
    <id>https://d0048.github.io/blog/2017/11/02/Prevent-Blocking-When-Using-PyPlot/</id>
    <published>2017-11-02T12:58:55.000Z</published>
    <updated>2017-11-02T13:05:28.205Z</updated>
    
    <content type="html"><![CDATA[<p>After display logic, call <code>imshow()</code> with parameter <code>block=False</code>.<br>2017/11/2</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;After display logic, call &lt;code&gt;imshow()&lt;/code&gt; with parameter &lt;code&gt;block=False&lt;/code&gt;.&lt;br&gt;2017/11/2&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="Python" scheme="https://d0048.github.io/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Thoughts For Possible New Network Structures</title>
    <link href="https://d0048.github.io/blog/2017/10/27/Thoughts-For-Possible-New-Network-Structures/"/>
    <id>https://d0048.github.io/blog/2017/10/27/Thoughts-For-Possible-New-Network-Structures/</id>
    <published>2017-10-27T14:21:03.000Z</published>
    <updated>2018-08-05T02:05:52.650Z</updated>
    
    <content type="html"><![CDATA[<h2 id="These-are-my-own-ideas-of-how-might-the-neural-network-architecture-may-be-improved-as-a-note-reminding-my-further-implementation-of-them"><a href="#These-are-my-own-ideas-of-how-might-the-neural-network-architecture-may-be-improved-as-a-note-reminding-my-further-implementation-of-them" class="headerlink" title="These are my own ideas of how might the neural network architecture may be improved, as a note reminding my further implementation of them"></a>These are my own ideas of how might the neural network architecture may be improved, as a note reminding my further implementation of them</h2><h3 id="Measure-for-Overfitting"><a href="#Measure-for-Overfitting" class="headerlink" title="Measure for Overfitting"></a>Measure for Overfitting</h3><p><strong><em>TODO</em></strong>: Add measure in respect to acc.<br><strong><em>TODO</em></strong>: Compare $O$ with normal CNN/DNN.</p><p>We does need some measure to see if/how the network is overfitting the training data.</p><p>My first thought is just use $O=LOSS(X_{train})-LOSS(X_{test})$. This seems to be working, and the value stays at around $0\pm0.04$, which means sometimes the network performs better in the training set($O&gt;0$) and sometimes the opposite($)&lt;0$).</p><p>However, after accuracy reaches $99.2\%$, the frequency of observing a positive overfit index $O$ increases and the average index also increase. </p><p><strong>To compare this index with the overfitting condition of other networks</strong>, I need to first somehow add the accuracy into the calculation of the index and then compare them on other architectures.<br>2017/11/21</p><h3 id="Generator-For-Cheating-a-Network"><a href="#Generator-For-Cheating-a-Network" class="headerlink" title="Generator For Cheating a Network"></a>Generator For Cheating a Network</h3><p>What would happen if we first train a classifier to classify image, and then train another network where it distort an input image to maximize the change in the estimation done by the fore-mentioned classifier at the same time minimize the distortion to the image?</p><p>This could be implemented using a new cost function for the second network.</p><p>Implementing.<br>2017/10/27</p><p>I failed to implement this structure in tensorflow in that rather than an actual value, I seems to be getting the uninitialized tensor representation of the output rather than the actual value and I failed to replace the input of the original network with that tensor.<br>2017/10/29</p><p>I found the Generative Adversarial Network (GAN) model which there isn’t that much of a difference between my idea and the model. However, using another network to probe the weak points of an existing network is likely to be a possible idea of improving it.<br>2017/10/30</p><p>This looks like a possible way of modifying the GAN model in that while the discriminator and the generator in the original GAN model works against each other, maybe we can make the discriminator to to create augmented data where it previously wrongly classified. Testing.<br>2017/10/31</p><p>I’m pretty sure this will work, but there are more to it. If I am to train a generator to modify the minimum amount to a picture and at the same time cheating the discriminator, this may work. However, if I am to use the modified image to retrain the network, things may not be as the same… A badly written <code>6</code> might be twisted into something like <code>8</code> from even human perspective and training the discriminator with the image of <code>8</code> and label of <code>6</code> is not likely to improve its performance.</p><p>However, adding the regularization term forcing the generated image to be different from the training set may be a good idea for generators to generate hopefully more creative samples. To be tested, too.<br>2017/11/1</p><p>This is indeed different from regular gan. It looks working but further experiments are to be done.<br>2017/11/2</p><p>Seems working. Work hanged for something else.<br>2017/11/8</p><p>This is called <code>Generative Poisoning Attack</code> and extensive research seems to has been performed on it.<br>2017/11/8</p><h2 id="Ambiguity-Measure-for-Dropout"><a href="#Ambiguity-Measure-for-Dropout" class="headerlink" title="Ambiguity Measure for Dropout"></a>Ambiguity Measure for Dropout</h2><p>Since increasing ambiguity is a good thing to do in ensembled classifiers, and dropout is essentially a cheap way to ensemble networks, why don’t we add another regularization term in the cost function to increase the ambiguity while dropout?<br>2017/11/1</p><h2 id="Certainty-Measure-for-the-Result"><a href="#Certainty-Measure-for-the-Result" class="headerlink" title="Certainty Measure for the Result"></a>Certainty Measure for the Result</h2><p>According to my observation, it’s weird that a classifier networks always give a clear indication of the result and there is no indication for “Uncertain”. In another word, it seems unlikely for multiple/none of the output nodes to fire at the same time.</p><p>The above may not necessarily be true, but it’s obvious that when a classifier network is given a sample that is totally different from any of the samples in the training set, the result tends to be coming from the weighted combination of the training examples. Will it be possible if we add another class to contain everything else and feed in random noises?</p><p>Unlikely to be useful.<br>2017/11/1</p><h3 id="Recursive-Conv-Net"><a href="#Recursive-Conv-Net" class="headerlink" title="Recursive Conv Net"></a>Recursive Conv Net</h3><p>What would happen is we make a convolution neural network recursive? Will this somehow benefit video generation?</p><p>To be tested.<br>2017/10/27</p><p>It exists…<br>2017/10/30</p><h2 id="Dynamic-Cost-Function"><a href="#Dynamic-Cost-Function" class="headerlink" title="Dynamic Cost Function"></a>Dynamic Cost Function</h2><p>Is it possible if we make the cost function dynamic and change according to the condition so the convergence could be faster? Or is it possible to even use RNN to generate cost function? How would that help? What change would that bring about?<br>To be tested.<br>2017/10/27</p><h3 id="Flip-network"><a href="#Flip-network" class="headerlink" title="Flip network"></a>Flip network</h3><p>According to <a href="https://arstechnica.com/civis/viewtopic.php?f=8&amp;t=785781" target="_blank" rel="external">here</a>, it looks like computers may have different speed between adding and subtracting numbers. If we flip the network so all addition became subtraction and vise versa (Then we might be maximizing the “cost” function), will it be any faster?</p><p>To be tested.<br>2017/10/27</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;These-are-my-own-ideas-of-how-might-the-neural-network-architecture-may-be-improved-as-a-note-reminding-my-further-implementation-of
      
    
    </summary>
    
    
      <category term="Thoughts" scheme="https://d0048.github.io/blog/tags/Thoughts/"/>
    
      <category term="Machine Learning" scheme="https://d0048.github.io/blog/tags/Machine-Learning/"/>
    
      <category term="Problem" scheme="https://d0048.github.io/blog/tags/Problem/"/>
    
  </entry>
  
</feed>
