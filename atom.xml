<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>D0048</title>
  
  <subtitle>A record of thoughts, ideas, solutions and traps</subtitle>
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="https://d0048.github.io/blog/"/>
  <updated>2017-10-17T07:38:47.772Z</updated>
  <id>https://d0048.github.io/blog/</id>
  
  <author>
    <name>D0048</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>The Harmonic Series: How Comes the Divergence</title>
    <link href="https://d0048.github.io/blog/2017/10/17/The-Harmonic-Series-how-comes-the-divergence/"/>
    <id>https://d0048.github.io/blog/2017/10/17/The-Harmonic-Series-how-comes-the-divergence/</id>
    <published>2017-10-17T07:24:42.000Z</published>
    <updated>2017-10-17T07:38:47.772Z</updated>
    
    <content type="html"><![CDATA[<h2 id="What-are-the-Harmonic-Series"><a href="#What-are-the-Harmonic-Series" class="headerlink" title="What are the Harmonic Series"></a>What are the Harmonic Series</h2><p>From Wikipedia, (Haronmic Series)[<a href="https://en.wikipedia.org/wiki/Harmonic_series_(mathematics" target="_blank" rel="external">https://en.wikipedia.org/wiki/Harmonic_series_(mathematics</a>)]</p><blockquote><p>In mathematics, the harmonic series is the divergent infinite series:<br>Its name derives from the concept of overtones, or harmonics in music:<br>the wavelengths of the overtones of a vibrating string are $1/2, 1/3, 1/4$<br>, etc., of the string’s fundamental wavelength. Every term of the<br>series after the first is the harmonic mean of the neighboring terms; the phrase harmonic mean likewise derives from music.</p></blockquote><p>It is basically a series defined like this:<br>$$<br>\sum_{x=0}^{\infinite}<br>$$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;What-are-the-Harmonic-Series&quot;&gt;&lt;a href=&quot;#What-are-the-Harmonic-Series&quot; class=&quot;headerlink&quot; title=&quot;What are the Harmonic Series&quot;&gt;&lt;/a&gt;Wh
      
    
    </summary>
    
    
      <category term="Math" scheme="https://d0048.github.io/blog/tags/Math/"/>
    
  </entry>
  
  <entry>
    <title>&quot;libcusolver.so.8.0: cannot open shared object file&quot; error while importing tensorflow</title>
    <link href="https://d0048.github.io/blog/2017/10/16/libcusolver-so-8-0-cannot-open-shared-object-file-error-while-importing-tensorflow/"/>
    <id>https://d0048.github.io/blog/2017/10/16/libcusolver-so-8-0-cannot-open-shared-object-file-error-while-importing-tensorflow/</id>
    <published>2017-10-16T08:18:46.000Z</published>
    <updated>2017-10-16T08:34:30.468Z</updated>
    
    <content type="html"><![CDATA[<p>After installing the gpu version of the tensorflow, I got this error while importing it:</p><pre>>>> import tensorflow as tfTraceback (most recent call last):  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py", line 41, in <module>    from tensorflow.python.pywrap_tensorflow_internal import *  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 28, in <module>    _pywrap_tensorflow_internal = swig_import_helper()  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 24, in swig_import_helper    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)  File "/usr/lib/python3.5/imp.py", line 242, in load_module    return load_dynamic(name, filename, file)  File "/usr/lib/python3.5/imp.py", line 342, in load_dynamic    return _load(spec)ImportError: libcusolver.so.8.0: cannot open shared object file: No such file or directory</module></module></pre><p>None of the solutions online, like setting the environmental variables to cuda installation.</p><p>I tried <code>locate libcusolver.so</code> and none of the paths refers to the version I wanted. This is because tensorflow only works with cuda 8.0 but the newest version of cuda is installed. (In my case, 8.0).</p><p>Because I am using ubuntu and installed cuda through ppa, I simply installed cuda 8.0 through <code>sudo apt-get install cuda-8-0</code> and everything worked. </p><p>2017/10/16</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;After installing the gpu version of the tensorflow, I got this error while importing it:&lt;/p&gt;
&lt;pre&gt;
&gt;&gt;&gt; import tensorflow as tf
Traceback 
      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="ML" scheme="https://d0048.github.io/blog/tags/ML/"/>
    
  </entry>
  
  <entry>
    <title>Difference Between Weights and Biases: Another way of Looking at Forward Propagation</title>
    <link href="https://d0048.github.io/blog/2017/10/14/Difference-Between-Weights-and-Biases-Another-way-of-Looking-at-Forward-propagation/"/>
    <id>https://d0048.github.io/blog/2017/10/14/Difference-Between-Weights-and-Biases-Another-way-of-Looking-at-Forward-propagation/</id>
    <published>2017-10-14T11:53:39.000Z</published>
    <updated>2017-10-15T12:08:19.805Z</updated>
    
    <content type="html"><![CDATA[<p>================LATEX MATH TEST================:<br>$$<br>\begin{eqnarray}<br>\nabla\times\vec{B} &amp;=&amp; \mu_0\left(\vec{J}+\epsilon_0\frac{\partial E}{\partial t} \right)<br>\end{eqnarray}<br>$$<br><em>IF THE ABOVE IS NOT SHOWING PROPERLY, PLEASE UNBLOCK UNSECURE(HTTP) CROSS SITE SCRIPTS IN YOUR BROWSER</em><br>================LATEX MATH TEST================:</p><h2 id="What-are-Weights-and-Biases"><a href="#What-are-Weights-and-Biases" class="headerlink" title="What are Weights and Biases"></a>What are Weights and Biases</h2><p>Consider the following forward propagation algorithm:<br>$$<br>\vec{y_{n}}=\mathbf{W_n}^T \times  \vec{y_{n-1}} + \vec{b_n}<br>$$<br>where $n$ is the number of the layers, $\vec{y_n}$ is the output of the $n^{th}$ layer, expressed as a $l_n \times 1$ ($l_n$ is the number of neurons of the $n^th$ layer) vector. $\mathbf{W_n}$ is a $l_{n-1} \times l_{n}$ matrix storing all the weights of every connection between layer $n$ and $n-1$, thus needing to be transposed for the sake of the product. $\vec{b_n}$, again, is the biases of the connections between the $n^th$ and $(n-1)^th$ layers, in the shape of $l_n\times1$.</p><p>As one can see, both weights and biases are just changeable and derivable(thus trainable) factors that contributes to the final results.</p><h2 id="Why-do-we-need-both-of-them-and-why-are-Biases-Optional"><a href="#Why-do-we-need-both-of-them-and-why-are-Biases-Optional" class="headerlink" title="Why do we need both of them, and why are Biases Optional?"></a>Why do we need both of them, and why are Biases Optional?</h2><p>Neural network, indeed a better version of the perceptron model, where the output of each neuron(perceptron) owns a linear correlation with the output, rather than simply outputting plain 0/1. (This relation is further more projected to the activation function to make it non-linear, which will be discussed later) </p><p>To create a linear correlation, the easiest way is to scale the input with a certain coefficient $w$, output the scaled input.<br>$$<br>f(x)=w\times x<br>$$</p><p>This model works alright, even with one neuron it could perfectly fit a linear function like $f(x)=m\times x$, and certain non-linear relations could be fit with neurons work in layers. </p><p>However, this new neuron without biases, lack of a significant ability even comparing to perceptron: it always fires regardless the input thus failing to fit functions like $y=mx+b$. It’s impossible to disable the output of a specific neuron on certain threshold value of the input. Even that adding more layers and neurons a lot eases and hides this issue, neural networks without biases are likely to perform a worse job than those with biases.(Consider the total layers/neurons are the same)</p><p>In conclusion, the biases are supplements to the weights to help a network better fit the pattern, which are not necessary but helps the network to perform better. </p><h2 id="Another-way-of-writing-the-Forward-Propagation"><a href="#Another-way-of-writing-the-Forward-Propagation" class="headerlink" title="Another way of writing the Forward Propagation"></a>Another way of writing the Forward Propagation</h2><p>Interestingly, the forward propagation algorithm<br>$$<br>\vec{y_{n}}=\mathbf{W_n}^T \times  \vec{y_{n-1}} + 1 \times \vec{b_n}<br>$$<br>could also be written like this:<br>$$<br>\vec{y_{n}}=<br>\left[ \begin{array}{c}<br>                x, \ 1<br>\end{array} \right]^T<br>\cdot<br>\left[ \begin{array}{c}<br>                \mathbf{W_n},<br>                \ \vec{b_n}<br>\end{array} \right]<br>$$,which is<br>$$<br>\vec{y_{n}} = \vec{y_{new_{n-1}}}^T \times \vec{W_{new}}<br>$$.<br>This is a way of rewriting the equation makes the adjustment by gradient really easy to write.</p><h2 id="How-to-update-them"><a href="#How-to-update-them" class="headerlink" title="How to update them?"></a>How to update them?</h2><p>It’s super easy after the rewrite:<br>$$<br>\vec{W_{new}} =\vec{W_{new}}-\frac{\delta W_{new}}{\delta Error}<br>$$.</p><h2 id="The-Activation-Function"><a href="#The-Activation-Function" class="headerlink" title="The Activation Function"></a>The Activation Function</h2><p>There is one more compoment yet to be mentioned–the Activation Function. It’s basically a function takes the output of a neuron as an input and output whatever value defined as the final output of the neuron.<br>$$<br>\vec{W_{new}} =Activation(\vec{W_{new}}-\frac{\delta W_{new}}{\delta Error})<br>$$<br>There are copious types of them around, but all of them have at least one shared property that there are all <em>Non-linear</em>! </p><p>That’s basically what they are designed for. Activation Functions project output to a non-linear function, thus introducing non-linearity into the model. </p><p>Consider non-linear-seperatable problems like the the XOR problem, giving the network the ability to draw non-linear sperators may help the classification.</p><p>Also, there’s another purpose of the activation function, which is to project a huge input, into the space between -1 and 1, thus making the followed-up calculations easier and faster.<br><br><br>2017/10/15</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;================LATEX MATH TEST================:&lt;br&gt;$$&lt;br&gt;\begin{eqnarray}&lt;br&gt;\nabla\times\vec{B} &amp;amp;=&amp;amp; \mu_0\left(\vec{J}+\epsilon
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://d0048.github.io/blog/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Pass Strings from Python to C/CPP libs</title>
    <link href="https://d0048.github.io/blog/2017/10/12/Pass-Strings-from-Python-to-C-CPP-libs/"/>
    <id>https://d0048.github.io/blog/2017/10/12/Pass-Strings-from-Python-to-C-CPP-libs/</id>
    <published>2017-10-12T00:49:35.000Z</published>
    <updated>2017-10-12T01:18:45.194Z</updated>
    
    <content type="html"><![CDATA[<p>Python strings are stored in the memory in a way smart but not c-friendly. There are two ways python strings could be stored:</p><ol><li><p>Non-specifically-encoded strings are usually stored as wide chars(<code>wchar</code>), where a string <code>&quot;test&quot;</code> in python basically looks like <code>&quot;t\0e\0s\0t\0&quot;</code>. This will mess with any functions in C relying on <code>\0</code> to find the end of a string(char*). </p></li><li><p>Encoded string are stored in the specified codec.</p></li></ol><p>Then, to pass a string object as <code>char*</code> or <code>wchar_t*</code> into native libiaries:</p><ol><li><p><code>import ctypes</code></p></li><li><p>Create the prototype of a function via <code>cdll_name.func_name.argtypes=[type,type,type]</code> to specify the types to pass. Use <code>ctypes.c_char_p</code> or <code>ctypes.c_wchar_p</code> to replace the type to specify the type wanted. A full lists of types could be found <a href="https://docs.python.org/3/library/ctypes.html" target="_blank" rel="external">here</a> under tag <code>16.16.1.4.</code>.</p></li><li><p>Call the function via <code>cdll_name.func_name(type(arg),type(arg)...)</code>. For example: <code>cdll_name.func_name(c_float(3.1),c_char_p(&quot;foo&quot;),c_wchar_p(&quot;bar&quot;))</code></p></li></ol><p>2017/10/12</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Python strings are stored in the memory in a way smart but not c-friendly. There are two ways python strings could be stored:&lt;/p&gt;
&lt;ol&gt;
&lt;l
      
    
    </summary>
    
    
      <category term="Python" scheme="https://d0048.github.io/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Some Thoughts on Deep Neural Networks and Handwritten digit recognition</title>
    <link href="https://d0048.github.io/blog/2017/10/05/Some-Thoughts-on-Deep-Neural-Networks-and-Handwritten-digit-recognition/"/>
    <id>https://d0048.github.io/blog/2017/10/05/Some-Thoughts-on-Deep-Neural-Networks-and-Handwritten-digit-recognition/</id>
    <published>2017-10-05T04:05:29.000Z</published>
    <updated>2017-10-05T04:06:16.823Z</updated>
    
    <content type="html"><![CDATA[<p>Classifying handwritten digits, from the traditional view of machine learning, using the Mnist dataset as an example, indeed classifying points on a (28*28=784) dimensional space into 10 separate classes, which is not necessarily linear seperateable .  </p><p>And the neural network we constructed (the most classical one, with a few fully-connected layers), is no difference than the fancier version of this program:  </p><p>The program above basically works like this:  <a href="https://github.com/D0048/makeyourownneuralnetwork/blob/master/better_detection/train.py" target="_blank" rel="external">https://github.com/D0048/makeyourownneuralnetwork/blob/master/better_detection/train.py</a></p><p>Imagine every picture in the training data set as an 28cm*28cm steal plate, where the darker areas are higher and the whiter areas are lower, with the elevation from 0cm to 255 cm (since the color value ranges from 0~255), or in another way more friendly to calculations, -127.5cm~+127.5cm.  Every steal plate should have an label with it for identification. </p><p>Generated image looks somehow like this (generated from <a href="http://cpetry.github.io/NormalMap-Online/" target="_blank" rel="external">http://cpetry.github.io/NormalMap-Online/</a>): </p><p>Label: 5 </p><p><img src="https://raw.githubusercontent.com/D0048/makeyourownneuralnetwork/master/better_detection/2828_my_own_5.png" width="200" height="200"><br><img src="https://raw.githubusercontent.com/D0048/makeyourownneuralnetwork/master/better_detection/5-3d.png" width="200" height="200"></p><p><br><br>Also, let we create another soft plate made of clay, specifically for the digit ‘5’, where all the initial elevations are 0. </p><p>Then, we collect all the steal plates in the training set labeled “5”, where the total number of them is marked as ‘m’. Smooth each of the steal plates in a scale of 1/m so that all the plates add up to be one plate. For example, the pixel with elevation 125 need to be smoothed into 125/m and the pixel with elevation –123 need to be smoothed into -125/m.  </p><p>After the steal plates are processed, we push it one by one on the clay model we prepared with matrix subtractions. There need to be a total of 10 plates for each digit. </p><p>At last, we pull out an random plate from the training set without reading the label on it, and push it into each of the 10 clay plates we prepare earlier corresponding to each digits, and measure the friction we meet push the steel plate into the clay. The one clay plate with the lowest friction while pushing our test sample inside is supposing to be corresponding to the actual digit represented by the sample.  </p><p>However, these current clay plates-“models” I call them-does not works well at all, considering the fact the a flat clay plate with elevation of –126 will give an virtually zero friction while applied by any sample and the more trainings are applied on a model, the more likely is the model to become flat and blurry and muddy thus making classification under satisfaction.  </p><p>One way to ease the problem is to reverse the rest of the training dataset that does not match the model so that the highest peek now become the lowest valley and apply them to this model again. However, this won’t address the issue from foundation and could somehow make the model more mushy.  </p><p>That’s the reason where the advantages of the neural network comes in, and why I called the neural network “a fancier version”. Basically, a neural network allows us to configure specific weights to each pixel so that the white areas around the actual digit (virtually) no longer contributes to the total friction (called error using former language)  and the black pixels shared by multiple digits, instead of a mess of blurry in our setup, contributes to the total friction in a smarter way, which is more like a black box. By making use of the multi-layer structure, we got a really flexible model that allows certain combination of pixels contributing to the final friction in a unified whole. Also, we can adapt universal methods like gradient descent to select the best weights for each neuron.  </p><p>However, this sounds a little bit strange and anti-intuitive: do we really need to map everything into such a high-dimensional space, in order to just classify 10 different digits? Neural networks seems to be somehow a mimic of brain, but my brain (at least mine) recognizing a digit does not seems to be relying on almost a thousand discrete features of that specific digit, no need to mention that the size of digits in real life could vary vastly according to multiple factors like distance. Do we really need all these features to perform the classification, or can we just first extract less but more pivotal features out the raw image? </p><p>After consideration, I suppose this means “narrower” networks, while deeper might serves as an compromise to it. Also, this means we may use multiple networks to work together in a chain, while some of them trying to extract the feature “smartly” from the data, and some others to deal with the final decision.  </p><p>It’s not until later that I read about the Convolution Neural Network, which is similar to the better neural network in my mind, as what descripted earlier. However, this is still not as expected—I expect a model that works more similar to our neural system, where it should be resistant to scaling (Current CNNs are not capable of doing so. A model called spatial transform network claimed to do so, to be researched) and there should not be such huge training set to reach a good performance. </p><p>Using handwritten digits as an example,  is that possible if we design a network to transform the digits into lines or even to Bézier curve. This way, the scaling problem is resolved. Then,  for ever entity, we can extract far more features rather than just pixels: the total number of close areas, the total interceptions… and so on.  This way, rather than letting the network treating a digit as an ambiguous picture(honestly I can’t even learn how to read digits with some 28*28 pictures), we may actually teach the network, in a more fundamental way, of what is a digit anyway.  </p><p>Recent new idea above, to be tested.  </p><p>Add:</p><p>Now I have somewhat more understanding on CNNs, and find them really powerful. However, it still somehow lack of resistance to size shift of objects. I have the following idea of improvement to be tested:</p><ol><li><p>Give the lower level features to CNNs, (like “does the sample have handle”), which matches our intuitive understanding, but use logic trees and other traditional machine learning methods to make the higher level decisions (like “is the sample a water bottle”), which matches our comprehensional understanding of objects. This may also prevent the network to use irrelevant features limited by the data in the training set. </p></li><li><p>Try different and irregular shapes of reception field, rather than just square. </p></li><li><p>Use another network like RNN to adjust learning rate. </p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Classifying handwritten digits, from the traditional view of machine learning, using the Mnist dataset as an example, indeed classifying 
      
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://d0048.github.io/blog/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Update pepper flash player under linux</title>
    <link href="https://d0048.github.io/blog/2017/09/24/update-pepper-flash-player-under-linux/"/>
    <id>https://d0048.github.io/blog/2017/09/24/update-pepper-flash-player-under-linux/</id>
    <published>2017-09-24T09:53:28.000Z</published>
    <updated>2017-09-24T09:54:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>Install of going for update using package manager, use <code>sudo update-pepperflashplugin-nonfree --install</code>.</p><p>ps: the most idiotic design ever :’</p><p>2017/9/24</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Install of going for update using package manager, use &lt;code&gt;sudo update-pepperflashplugin-nonfree --install&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;ps: the most 
      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="Flash" scheme="https://d0048.github.io/blog/tags/Flash/"/>
    
  </entry>
  
  <entry>
    <title>Convert an image into an XBitMap C array stored in a C header file</title>
    <link href="https://d0048.github.io/blog/2017/09/12/convert-an-image-into-an-xbitmap-array/"/>
    <id>https://d0048.github.io/blog/2017/09/12/convert-an-image-into-an-xbitmap-array/</id>
    <published>2017-09-12T12:52:52.000Z</published>
    <updated>2017-09-12T12:56:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>==<a href="https://stackoverflow.com/questions/2156572/c-header-file-with-bitmapped-fonts/2156872#2156872" target="_blank" rel="external">Credit: StackOverflow</a>==</p><p>Basically, install <code>imagemagick</code>, and use the shell command: <code>convert $source.png $dest.xbm</code>….</p><p>This is a really simple solution but takes me hours to really figure things out.</p><p>2017/9/12 21:00</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;==&lt;a href=&quot;https://stackoverflow.com/questions/2156572/c-header-file-with-bitmapped-fonts/2156872#2156872&quot; target=&quot;_blank&quot; rel=&quot;external&quot;
      
    
    </summary>
    
    
      <category term="C" scheme="https://d0048.github.io/blog/tags/C/"/>
    
      <category term="Xorg" scheme="https://d0048.github.io/blog/tags/Xorg/"/>
    
  </entry>
  
  <entry>
    <title>A key point understanding single variable chain rule</title>
    <link href="https://d0048.github.io/blog/2017/09/12/a-key-point-understanding-single-variable-chain-rule/"/>
    <id>https://d0048.github.io/blog/2017/09/12/a-key-point-understanding-single-variable-chain-rule/</id>
    <published>2017-09-12T12:33:25.000Z</published>
    <updated>2017-09-12T12:37:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>A key point understanding single variable chain rule: </p><p>f(g(x)) = f’(g)*g’ </p><p>At f’(g) part, g is inserted into f’ as a macro <strong>==after==</strong> taking the derivative!!!!! </p><p>e.g:</p><pre>f(x)=a^2g(x)=2af'(g), instead of dx((2a)^2) /dyis actually: "dx(a^2)/dy".replace("a","2a") !!!</pre><p>2017/9/12 20:30</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;A key point understanding single variable chain rule: &lt;/p&gt;
&lt;p&gt;f(g(x)) = f’(g)*g’ &lt;/p&gt;
&lt;p&gt;At f’(g) part, g is inserted into f’ as a macro 
      
    
    </summary>
    
    
      <category term="Math" scheme="https://d0048.github.io/blog/tags/Math/"/>
    
  </entry>
  
  <entry>
    <title>Change screen saver image on a rooted kindle pw2 manually without installing any more hacks</title>
    <link href="https://d0048.github.io/blog/2017/09/09/change-wall-papers-on-a-rooted-kindle-manually-without-installing-any-more-hacks/"/>
    <id>https://d0048.github.io/blog/2017/09/09/change-wall-papers-on-a-rooted-kindle-manually-without-installing-any-more-hacks/</id>
    <published>2017-09-09T01:43:08.000Z</published>
    <updated>2017-09-09T01:58:21.000Z</updated>
    
    <content type="html"><![CDATA[<p>I am just tired with the screensaver images and the ads thus trying to change them up. Also, I don’t want any more hack packages without really checking what’s inside myself. </p><p>First of all, connect to the shell of that kindle using whatever methods possible.(e.g: xterm)</p><p>The original wall papers seems to be located at <code>/user/share/blanket/screensaver/</code>. By replacing them with my own, I should be able to use my own images.</p><p>However, the file system there seems to be mounted as read only. Use <code>df /user/share/blanket/screensaver/</code> to locate the mounting point and remount it with <code>mount -o remount,rw /</code>(coz in my case it mounted together with <code>/</code>)</p><p>Then, one could freely copy his/her images(should be in the right size) into that folder following the name sequence. </p><p>2017/9/9</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;I am just tired with the screensaver images and the ads thus trying to change them up. Also, I don’t want any more hack packages without 
      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="Kindle" scheme="https://d0048.github.io/blog/tags/Kindle/"/>
    
  </entry>
  
  <entry>
    <title>Solve </title>
    <link href="https://d0048.github.io/blog/2017/09/05/solve-missingsectionheadererror-file-contains-no-section-headers-in-configphaser-pyhton/"/>
    <id>https://d0048.github.io/blog/2017/09/05/solve-missingsectionheadererror-file-contains-no-section-headers-in-configphaser-pyhton/</id>
    <published>2017-09-05T12:44:57.000Z</published>
    <updated>2017-09-05T12:51:27.000Z</updated>
    
    <content type="html"><![CDATA[<p>While reading config files with utf-8 BOM header, configphaser throws this confusing exception. </p><p>While most of the online solutions suggests manually change the encoding of the file to ANSCII, or read the file and save it again in another format. The former drops support to special characters and the latter is just not easy enough.</p><p>I found that the default ConfigPhaser uses non-encoded format. In order to make sure it reads the file in the correct format:<br><code>configphaser.ConfigPhaser().read(config_file, encoding=&quot;utf-8-sig&quot;)</code></p><p>This should tell the phaser to use the utf-8 encoding with bom.</p><p>2017/9/5</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;While reading config files with utf-8 BOM header, configphaser throws this confusing exception. &lt;/p&gt;
&lt;p&gt;While most of the online solution
      
    
    </summary>
    
    
      <category term="Python" scheme="https://d0048.github.io/blog/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Concerns Over a Trend of Online-compiled Application Dev Platforms</title>
    <link href="https://d0048.github.io/blog/2017/09/03/cong-e-ni-cong-er-neng-sui/"/>
    <id>https://d0048.github.io/blog/2017/09/03/cong-e-ni-cong-er-neng-sui/</id>
    <published>2017-09-03T05:58:42.000Z</published>
    <updated>2017-09-03T06:01:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>Along the higher levels of abstract of the hardware, programming tends to become easier and more universal, together with acceptable amount of performance lost. Overall, such observation is a good thing to have since it make everyone’s life easier.  </p><p>However, this could actually cause many security/privacy issues. Using my experience in the summer camp as an example, where we were asked to perform all our developments on an “environment” made by a company called Apicloud(As I was told, there are tons of similar platforms available but they are essentially the same thing). This is a platform where you can create gui phone applications using simple js language and the api the company provided. All the low level code are packaged into so-called “modules”(named by the company). The key point is, those modules are provided by third party, non-open source, and not even accessible to the ones who use it. All the so-called “compilation and build” are performed online, by uploading user code to a repo binds to this user’s account and send an build request over a webpage panel.  </p><p>This is actually a really bad signal—developers no longer know what happened to the project and they just upload their code(more like pseudo-code thou) and depending on some third-party companies in responsible for the rest. One shall never know what has been added into one’s application packages to make an 3-line hello world program larger than 30mb and starts automatically on phone boot. What might be inside? Backdoors? ADs? Or user trackers? We shall never know! Moreover, the account of every developer is forced to bonded to his/er phone number, which is further forced to bonded to his/er ID number. This way, it would be a huge privacy issue in that the gov shall now know who, at where is making those applications, and have the total ability to disable one’s ability to further produce/use any applications by deleting his/er account and disable their applications.  </p><p>This way, users and developers are all losing their control over their applications, instead giving the right to some kinds of third-party organization! </p><p>Moreover, according to my observation, tons of popular, rather lower scale applications, are all based on similar platforms! We shall be aware of what is going on!</p><p>2017/9/3 14:00</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Along the higher levels of abstract of the hardware, programming tends to become easier and more universal, together with acceptable amou
      
    
    </summary>
    
    
      <category term="Security" scheme="https://d0048.github.io/blog/tags/Security/"/>
    
      <category term="Thought" scheme="https://d0048.github.io/blog/tags/Thought/"/>
    
  </entry>
  
  <entry>
    <title>Casting java obj[] into String[]</title>
    <link href="https://d0048.github.io/blog/2017/08/02/casting-java-obj-into-string/"/>
    <id>https://d0048.github.io/blog/2017/08/02/casting-java-obj-into-string/</id>
    <published>2017-08-02T05:42:54.000Z</published>
    <updated>2017-08-02T05:46:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>In java, an object array can not be directly cast into a string array. This problem usually occurs when getting an array from a collection. </p><p>According to <a href="https://stackoverflow.com/questions/22731706/java-lang-classcastexception-ljava-lang-object-cannot-be-cast-to-ljava-lang" target="_blank" rel="external">this post</a>It’s possible to do it like this:<br><code>String[] str = someCollection.toArray(new String[someCollection.size()]);</code></p><p>2017.8.2</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;In java, an object array can not be directly cast into a string array. This problem usually occurs when getting an array from a collectio
      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="Java" scheme="https://d0048.github.io/blog/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>vim plugin Syntastic works without error or effect</title>
    <link href="https://d0048.github.io/blog/2017/07/20/vim-plugin-syntastic-works-without-error-or-effect/"/>
    <id>https://d0048.github.io/blog/2017/07/20/vim-plugin-syntastic-works-without-error-or-effect/</id>
    <published>2017-07-20T06:53:15.000Z</published>
    <updated>2017-07-20T06:57:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>Compile YouCompleteMe again with extra flag: <code>./install.sh --clang-completer</code>.</p><p>2017/7/20</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Compile YouCompleteMe again with extra flag: &lt;code&gt;./install.sh --clang-completer&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;2017/7/20&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
      <category term="Vim" scheme="https://d0048.github.io/blog/tags/Vim/"/>
    
  </entry>
  
  <entry>
    <title>Audio device disabled and replaced by dummy audio after using hdajackretask</title>
    <link href="https://d0048.github.io/blog/2017/07/11/audio-device-disabled-and-replaced-by-dummy-audio-after-using-hdajackretask/"/>
    <id>https://d0048.github.io/blog/2017/07/11/audio-device-disabled-and-replaced-by-dummy-audio-after-using-hdajackretask/</id>
    <published>2017-07-11T02:57:33.000Z</published>
    <updated>2017-07-11T03:12:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>After some modification on <code>hdajackretask</code>, which previously worked but disabled my audio card after reboot(in both dual of windows 10 and ubuntu).</p><p>Ubuntu will reports an error of <code>codecs not found</code> and windows will return an error of <code>device moved</code>.</p><p>In my case, this problem is solved through editing <code>/etc/modprobe.d/alsa-base.conf</code> in that the desired audio card is marked with <code>index=-2</code>.</p><p>By changing the index of the desired interface to ‘1’,(in my case, the one with <code>intel</code> in it because I am using <code>snd-hda-intel</code> ) and adding <code>options snd-hda-intel model=auto</code>, the problem is resolved after reboot. </p><p>2017/7/11</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;After some modification on &lt;code&gt;hdajackretask&lt;/code&gt;, which previously worked but disabled my audio card after reboot(in both dual of wi
      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>A few points need to be caution while using crypt() in c</title>
    <link href="https://d0048.github.io/blog/2017/06/13/a-few-points-need-to-be-caution-while-using-crypt-in-c/"/>
    <id>https://d0048.github.io/blog/2017/06/13/a-few-points-need-to-be-caution-while-using-crypt-in-c/</id>
    <published>2017-06-13T00:48:16.000Z</published>
    <updated>2017-06-13T01:09:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>While using this function, there’s a lot that’s mentioned in the manual but hard to find.</p><p>From manual:</p><pre>#define _XOPEN_SOURCE        /* See feature_test_macros(7) */#include <unistd.h>char *crypt(const char *key, const char *salt);#define _GNU_SOURCE          /* See feature_test_macros(7) */#include <crypt.h>char *crypt_r(const char *key, const char *salt,struct crypt_data *data);Link with -lcrypt.</crypt.h></unistd.h></pre><p>However:</p><pre>The return value points to static data whose contentis overwritten by each call.</pre>This means a strdup or similar operation is necessary to copy it if one want to preserve the value and use the previous after another crypt. Also, it is not in the manual that using an encrypted string as salt means using the same salt that encrypts the string is used to encrypt the new one. The reason is that the string output will have its own salt at its beginning. The manual mentions nothing about how the check works but it works at here. So I looked for the source code in c posix library(From here:https://code.woboq.org/userspace/glibc/crypt/crypt-entry.c.html#crypt):<pre>157    char *158    crypt (const char *key, const char *salt)159    {160    #ifdef _LIBC161      /* Try to find out whether we have to use MD5 encryption replacement.  */162      if (strncmp (md5_salt_prefix, salt, sizeof (md5_salt_prefix) - 1) == 0163          /* Let __crypt_r deal with the error code if FIPS is enabled.  */164          && !fips_enabled_p ())165        return __md5_crypt (key, salt);166    167      /* Try to find out whether we have to use SHA256 encryption replacement.  */168      if (strncmp (sha256_salt_prefix, salt, sizeof (sha256_salt_prefix) - 1) == 0)169        return __sha256_crypt (key, salt);170    171      /* Try to find out whether we have to use SHA512 encryption replacement.  */172      if (strncmp (sha512_salt_prefix, salt, sizeof (sha512_salt_prefix) - 1) == 0)173        return __sha512_crypt (key, salt);174    #endif175    176      return __crypt_r (key, salt, &_ufc_foobar);177    }</pre><p>It seems to be smarter than I excepted and can even determine which way to encrypt according to the salt….</p><p>2017/6/13</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;While using this function, there’s a lot that’s mentioned in the manual but hard to find.&lt;/p&gt;
&lt;p&gt;From manual:&lt;/p&gt;
&lt;pre&gt;
#define _XOPEN_SO
      
    
    </summary>
    
    
      <category term="C" scheme="https://d0048.github.io/blog/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>How to have two header files contain each other to use the others&#39; class</title>
    <link href="https://d0048.github.io/blog/2017/05/17/how-to-have-two-header-files-contain-each-other-to-use-the-others-class-2/"/>
    <id>https://d0048.github.io/blog/2017/05/17/how-to-have-two-header-files-contain-each-other-to-use-the-others-class-2/</id>
    <published>2017-05-17T08:47:15.000Z</published>
    <updated>2017-05-17T09:00:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>When 2 <code>.h</code> files are trying to use classes in each other, an error will occur if no special treatment is applied:</p><pre> syntax error : identifier "class_name"</pre>It seems like the compiler identify the class as an identifier. I tried to use macro commands like the following <pre>#ifndef PACKAGE#include "Package.h"#define PACKAGE#endif</pre>==But failed.==With the help of this [passage](http://www.bijishequ.com/detail/149692?p=), I found a way to solve it. A class in C++ can be first declared and then defined like this:<pre>class class_name;//this is a declaration.class class_name{    Content contents;};//this is a definition</pre><p>So by putting only the declaration of classes in the header files or by putting another declaration of the class before use, it is made possible for this problem to be solved.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;When 2 &lt;code&gt;.h&lt;/code&gt; files are trying to use classes in each other, an error will occur if no special treatment is applied:&lt;/p&gt;
&lt;pre&gt;
 
      
    
    </summary>
    
    
      <category term="CPP" scheme="https://d0048.github.io/blog/tags/CPP/"/>
    
  </entry>
  
  <entry>
    <title>MACHINE LEARNING ARE REALLY ADVANCING THESE DAYS</title>
    <link href="https://d0048.github.io/blog/2017/05/15/machine-learning-are-really-advancing-these-days/"/>
    <id>https://d0048.github.io/blog/2017/05/15/machine-learning-are-really-advancing-these-days/</id>
    <published>2017-05-15T13:03:57.000Z</published>
    <updated>2017-05-15T13:16:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, I formed a strong interest on machine learning in that it provides a new way to view the relationship between how programs view the world and how we view the world. Even if digging the detail requires a strong math knowledge, which I don’t have yet, by reading basic concepts, I can have a grasp of the idea. I believe it might be the future of computers.</p><p>Leave out how this subject is powerful since I am just beginning my first contact with it, let’s look at how much has been done through it. For example, it allows programs to learn from the past and form new knowledge. I went through a paper called “Major Life Event Extraction from Twitter based on Congratulations/Condolences Speech Acts” and I found that a lot more could be done with appropriate machine learning strategies. It is almost unimaginable before for a program to identify intents inside texts used by humans and now it’s made possible by machine learning. That’s cool.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Recently, I formed a strong interest on machine learning in that it provides a new way to view the relationship between how programs view
      
    
    </summary>
    
    
      <category term="Thoughts" scheme="https://d0048.github.io/blog/tags/Thoughts/"/>
    
  </entry>
  
  <entry>
    <title>Important stuff about the crypt() function in crypt.h under linux</title>
    <link href="https://d0048.github.io/blog/2017/05/13/important-stuff-about-the-crypt-function-in-crypt-h-under-linux/"/>
    <id>https://d0048.github.io/blog/2017/05/13/important-stuff-about-the-crypt-function-in-crypt-h-under-linux/</id>
    <published>2017-05-13T04:15:08.000Z</published>
    <updated>2017-05-25T07:30:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>The <code>char* crypt(char*salt, char* str);</code> function is used for one-way encryption with salt.  However, the buffer it returns is always the same piece of memory so it may appear to be returning duplicated results.</p><p>Solution: Use <code>strcp()</code> or <code>strdup()</code> to make a copy of the result every-time after invokes. Also, remember to free the memory after use. </p><p>Example:</p><p><pre><br>char<em> a = crypt(“string1”,”this_is_salt”);<br>char</em> b = crypt(“string2”,”this_is_salt”);<br>printf(“%s”, strcmp(a,b));<br></pre><br>The above is a wrong example and will print 0;</p><p><pre><br>char<em> a = strdup(crypt(“string1”,”this_is_salt”));<br>char</em> b = strdup(crypt(“string2”,”this_is_salt”));<br>printf(“%s”, strcmp(a,b));<br>free(a);free(b);<br></pre><br>The above is a correct example and will print a non-0 value;</p><p>2017/5/25</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;The &lt;code&gt;char* crypt(char*salt, char* str);&lt;/code&gt; function is used for one-way encryption with salt.  However, the buffer it returns is
      
    
    </summary>
    
    
      <category term="C" scheme="https://d0048.github.io/blog/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Migrate/Share everything between vivaldi and chrome under linux</title>
    <link href="https://d0048.github.io/blog/2017/05/12/migrate-everything/"/>
    <id>https://d0048.github.io/blog/2017/05/12/migrate-everything/</id>
    <published>2017-05-12T06:13:26.000Z</published>
    <updated>2017-05-12T06:45:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>I just found the vivaldi browser, which based on chromium, works really good for me. Thus I need to find a way to migrate. Here we go:</p><ol><li><p>Find a config file of chrome, usually located under <code>~/.config/google-chrome</code>|~<code>~/.config/google-chrome-beta</code>|<code>~/.config/chromium</code> or similar places.</p></li><li><p>Create a soft link of the folder called <code>default</code> with <code>ln -s</code> or whatever method preferred. </p></li><li><p>Run vivaldi once and close it to generate proper configuration files.</p></li><li><p>Locate the vivaldi config file, usually located under <code>~/.config/vivaldi</code>.</p></li><li><p>Delete the <code>default</code> folder under <code>~/.config/vivaldi</code>.</p></li><li><p>Copy the softlink just created here and name it <code>default</code>.</p></li><li><p>Till now, we got everything but stored password in the browser migrated successfully. If preferred, copy the whole <code>default</code> folder from chrome and override the one for vivaldi will do the same trick but prevent sharing config files.</p></li><li><p>Also, copy all the content under<br><code>~/.config/google-chrome</code>|~<code>~/.config/google-chrome-beta</code>|<code>~/.config/chromium</code> <br><br>into<br><code>~/.config/vivaldi</code><br>litereally </p></li></ol><p>==For now, no automatic way to make importing password possible. However, one can manually do so….==<br><br>2017/5/12</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;I just found the vivaldi browser, which based on chromium, works really good for me. Thus I need to find a way to migrate. Here we go:&lt;/p
      
    
    </summary>
    
    
      <category term="Solution" scheme="https://d0048.github.io/blog/tags/Solution/"/>
    
  </entry>
  
  <entry>
    <title>Meanings of abnormal memories value in visual studio under debug mode</title>
    <link href="https://d0048.github.io/blog/2017/05/11/meanings-of-memory-excpetion-in-visual-studio-under-debug-mode/"/>
    <id>https://d0048.github.io/blog/2017/05/11/meanings-of-memory-excpetion-in-visual-studio-under-debug-mode/</id>
    <published>2017-05-11T11:42:58.000Z</published>
    <updated>2017-05-11T11:51:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>Thanks for the ide tool, the environment is controlled to provide faster problem locationg function.</p><p>As I quote from msdn:</p><pre>* 0xcccccccc : Used by Microsoft's C++ debugging runtime library to mark uninitialised stack memory = (char)'烫'</pre><pre>* 0xcdcdcdcd : Used by Microsoft's C++ debugging runtime library to mark uninitialised heap memory = (char)'屯'</pre><pre>* 0xfeeefeee : Used by Microsoft's HeapFree() to mark freed heap memory</pre><pre>* 0xabababab : Used by Microsoft's HeapAlloc() to mark "no man's land" guard bytes after allocated heap memory</pre><pre>* 0xabadcafe : A startup to this value to initialize all free memory to catch errant pointers</pre><pre>* 0xbaadf00d : Used by Microsoft's LocalAlloc(LMEM_FIXED) to mark uninitialised allocated heap memory</pre><pre>* 0xbadcab1e : Error Code returned to the Microsoft eVC debugger when connection is severed to the debugger</pre><pre>* 0xbeefcace : Used by Microsoft .NET as a magic number in resource files</pre><p>These will be useful for bebugging!<br>2017/5/11</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Thanks for the ide tool, the environment is controlled to provide faster problem locationg function.&lt;/p&gt;
&lt;p&gt;As I quote from msdn:&lt;/p&gt;
&lt;pr
      
    
    </summary>
    
    
      <category term="Debug" scheme="https://d0048.github.io/blog/tags/Debug/"/>
    
  </entry>
  
</feed>
